{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Synopsis\n",
    "\n",
    "So far we have essentially only learned how to parse and enumerate the number of words in text (doesn't sound like much, huh? But that alone comprises a large amount of basic textual analysis). In this unit we will go a bit further and cover:\n",
    "\n",
    "1. Preparing text for further analysis\n",
    "2. Analyzing sentiment\n",
    "\n",
    "We will also talk about how difficult advanced analysis of unstructured text is despite its appearance as an 'easy' task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T18:29:15.811763Z",
     "start_time": "2023-08-04T18:29:15.243055Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from colorama import Back, Fore, Style\n",
    "from copy import copy, deepcopy\n",
    "from pathlib import Path\n",
    "from sys import path\n",
    "\n",
    "path.append( str(Path.cwd().parent) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T18:29:20.383322Z",
     "start_time": "2023-08-04T18:29:17.398179Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from random import random\n",
    "from string import punctuation, whitespace\n",
    "\n",
    "from Amaral_libraries.my_stats import half_frame\n",
    "from Amaral_libraries.my_nlp_library import ( read_complete_works, \n",
    "                                              get_characters, \n",
    "                                              get_character_lines,\n",
    "                                              extract_words_from_lines, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T18:29:27.937607Z",
     "start_time": "2023-08-04T18:29:27.850430Z"
    }
   },
   "outputs": [],
   "source": [
    "my_fontsize = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text emotional valence\n",
    "\n",
    "The notebook about the basics of text analysis illustrated some of the kinds of analyses that one can perform on text corpora.  The focus there was on simple calculations based on patterns of occurrence of work tokens.  Probably, not very satisfying for English or Psychology majors...\n",
    "\n",
    "In this notebook, we are going to skim the surface of a different type of analysis.  Whether the text has positive, neutral, or negative **valence**.  This is typically referred to as **sentiment analysis**. The idea is that while most words are neutral some words convey valence in a polarized manner.  \n",
    "\n",
    "*Sadness*, *anger*, *despair* convey a very different emotion from *happiness*, *laughter*, or *brightness*.\n",
    "\n",
    "This realization has been formalized by asking many subjects to rate the valence of different words.  The aggregated ratings were then structured into lists where words are given a valence score.\n",
    "\n",
    "Fortunately for us, such work is summarized in data files we can easily access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T18:29:32.256172Z",
     "start_time": "2023-08-04T18:29:32.182140Z"
    }
   },
   "outputs": [],
   "source": [
    "afinn_folder = Path.cwd() / 'Data' / 'AFINN'\n",
    "\n",
    "print( list( afinn_folder.glob('*') ) )\n",
    "print()\n",
    "\n",
    "valences_file_path = afinn_folder / 'AFINN-111.txt'\n",
    "with open(valences_file_path, 'r', encoding = 'utf-8') as file_in:\n",
    "    valence_data = file_in.readlines() \n",
    "\n",
    "print(len(valence_data))\n",
    "print()\n",
    "\n",
    "print(valence_data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That needs a little processing, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T18:29:40.257129Z",
     "start_time": "2023-08-04T18:29:40.206367Z"
    }
   },
   "outputs": [],
   "source": [
    "valence_dict  = {}\n",
    "for line in valence_data:\n",
    "    token, valence = line.split()\n",
    "    print(token, valence)\n",
    "    valence_dict[token.strip()] = float(valence.strip())\n",
    "    print(valence_dict)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good.\n",
    "\n",
    "Let's remove the `print` and `break` statements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T18:29:43.719541Z",
     "start_time": "2023-08-04T18:29:43.511414Z"
    }
   },
   "outputs": [],
   "source": [
    "valence_dict  = {}\n",
    "for line in valence_data:\n",
    "    token, valence = line.split()\n",
    "    valence_dict[token.strip()] = float(valence.strip())\n",
    "    \n",
    "print(len(valence_dict))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damn! Some lines do not have just two parts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T18:29:53.422934Z",
     "start_time": "2023-08-04T18:29:53.385168Z"
    }
   },
   "outputs": [],
   "source": [
    "valence_dict  = {}\n",
    "for line in valence_data:\n",
    "    if len(line.split()) == 2:\n",
    "        token, valence = line.split()\n",
    "    else:\n",
    "        print(line.split())\n",
    "    valence_dict[token.strip()] = float(valence.strip())\n",
    "    \n",
    "print(len(valence_dict))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Damn!!! Damn!!!**\n",
    "\n",
    "Some of the tokens are not single words.\n",
    "\n",
    "What do you say if we ignore them for now?  We can still read them by noting that a `\\t` character separates the token from the valence, but we will pretend they are not there for the rest of the work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T18:30:01.343672Z",
     "start_time": "2023-08-04T18:30:01.295161Z"
    }
   },
   "outputs": [],
   "source": [
    "valence_dict  = {}\n",
    "for line in valence_data:\n",
    "    token, valence = line.strip().split('\\t')\n",
    "    valence_dict[token.strip()] = float(valence.strip())\n",
    "    \n",
    "print(len(valence_dict)) \n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some words for sure are in this `dictionary`, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T21:55:04.551476Z",
     "start_time": "2023-02-12T21:55:04.498042Z"
    }
   },
   "outputs": [],
   "source": [
    "valence_dict['hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T21:55:05.517574Z",
     "start_time": "2023-02-12T21:55:05.468222Z"
    }
   },
   "outputs": [],
   "source": [
    "valence_dict['happy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T21:55:06.579035Z",
     "start_time": "2023-02-12T21:55:06.525180Z"
    }
   },
   "outputs": [],
   "source": [
    "valence_dict['screwed up']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A detour for creating our own_library\n",
    "\n",
    "I would like us to work with the play **Othello, the moor of Venice**. We could go back to the *basics* notebook but that is silly. Why would we want to keep a large number of versions of the same code across many notebooks?\n",
    "\n",
    "For one, improvements made in one copy do not transfer to all the other copies.\n",
    "\n",
    "For another, opening the other notebook and copying and pasting the code is annoying and creates issues if we forget to load some needed library.\n",
    "\n",
    "So, how to solve this?\n",
    "\n",
    "**Well, we will create our own library!!!!**\n",
    "\n",
    "Go to the notebook with the folder contents of the current working directory and create a new text file\n",
    "\n",
    "<img src = 'Images/create_library_step1.png'>\n",
    "\n",
    "This will create a new file and open it.\n",
    "\n",
    "You then would change its name.\n",
    "\n",
    "<img src = 'Images/create_library_step2.png'>\n",
    "\n",
    "You will notice that the file type has changed now to `Python`.\n",
    "\n",
    "Inside, you can add the functions you want.  I wrote a bunch of them from our prior work.\n",
    "\n",
    "<img src = 'Images/create_library_step3.png'>\n",
    "\n",
    "Don't forget to save (under `File` on the top left corner).\n",
    "\n",
    "Your new library file is now available in your folder.\n",
    "\n",
    "<img src = 'Images/create_library_step4.png'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We already imported this library above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T21:58:27.748810Z",
     "start_time": "2023-02-12T21:58:27.704236Z"
    }
   },
   "outputs": [],
   "source": [
    "help(read_complete_works)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So professional looking ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yes! Othello again!\n",
    "\n",
    "Ok, let's load everything that we need to work with this play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T21:58:40.993044Z",
     "start_time": "2023-02-12T21:58:40.891230Z"
    }
   },
   "outputs": [],
   "source": [
    "shapespeare_path = Path.cwd() / 'Data' / 'Shakespeare.txt'\n",
    "\n",
    "complete_works, plays = read_complete_works()\n",
    "plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T21:58:44.957922Z",
     "start_time": "2023-02-12T21:58:44.911996Z"
    }
   },
   "outputs": [],
   "source": [
    "title = 'THE TRAGEDY OF OTHELLO, MOOR OF VENICE'\n",
    "start_line = plays[title][1]\n",
    "end_line = plays[title][2]\n",
    "othello_play = complete_works[start_line: end_line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T21:59:22.146200Z",
     "start_time": "2023-02-12T21:59:22.096324Z"
    }
   },
   "outputs": [],
   "source": [
    "personae = get_characters(othello_play)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WE ARE READY TO GO!!!**\n",
    "\n",
    "Let's look at what is going on with Othello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T21:59:35.203675Z",
     "start_time": "2023-02-12T21:59:35.147554Z"
    }
   },
   "outputs": [],
   "source": [
    "othello_lines = get_character_lines('OTHELLO', othello_play)\n",
    "\n",
    "print(len(othello_lines))\n",
    "print()\n",
    "\n",
    "print(othello_lines[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:00:00.341382Z",
     "start_time": "2023-02-12T22:00:00.290195Z"
    }
   },
   "outputs": [],
   "source": [
    "othello_words = extract_words_from_lines('Othello', othello_lines)\n",
    "\n",
    "print(len(othello_words))\n",
    "print()\n",
    "\n",
    "print(othello_words[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating emotional valences\n",
    "\n",
    "Now that we have Othello's words, we can compare them to the keys of the valence dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:00:04.959625Z",
     "start_time": "2023-02-12T22:00:04.906804Z"
    }
   },
   "outputs": [],
   "source": [
    "valence = 0\n",
    "count = 0\n",
    "corpus = othello_words[:]\n",
    "for word in corpus:\n",
    "    if word in valence_dict.keys():\n",
    "#         print(f\"{word:>20} -- {valence_dict[word]}\")\n",
    "        count += 1\n",
    "        valence += valence_dict[word]\n",
    "        \n",
    "print(f\"\\n\\nThe valence of the provided corpus is {valence / count:.3f}\") \n",
    "\n",
    "print(f\"\\nOut of {len(corpus)} words, {count} had a non-zero valence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that fewer than 10% of words have a non-zero valence. \n",
    "\n",
    "There are a other problems, however. *Very happy* should have higher valence than *happy*. And *not happy* should have a negative valence.  \n",
    "\n",
    "Our bag-of-words approach does not account for these possibilities.\n",
    "\n",
    "Let's ignore that issue for now, and attempt to check whether the valence of Othello's speech changes in the course of the play.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time dependence\n",
    "\n",
    "We will do a little trick for this.\n",
    "\n",
    "We will consider blocks of 200 words and move them by steps of 50 words.  This will smooth things a bit and give us some idea of whether there is a change or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:00:18.066614Z",
     "start_time": "2023-02-12T22:00:17.847773Z"
    }
   },
   "outputs": [],
   "source": [
    "times = []\n",
    "valences = []\n",
    "corpus = othello_words\n",
    "step = 50\n",
    "window = 500 \n",
    "\n",
    "for i in range(0, len(corpus)-window, step): \n",
    "    temp_corpus = corpus[i:i+int(window / 2)]\n",
    "    count = 0\n",
    "    valence_t = 0\n",
    "    for word in temp_corpus:\n",
    "        if word in valence_dict.keys():\n",
    "            count += 1\n",
    "            valence_t += valence_dict[word]\n",
    "            \n",
    "    times.append(i + int(window / 2))\n",
    "    valences.append(valence_t / count)\n",
    "        \n",
    "fig = plt.figure( figsize = (6, 4) )\n",
    "ax = fig.add_subplot( 111 )\n",
    "half_frame(ax, 'Word count', 'Emotional valence', font_size = my_fontsize)\n",
    "# Guide to the eye\n",
    "ax.plot([0, 6500], [0, 0], 'k--', lw = 2)\n",
    "ax.fill_between([0, 6500], -2, color = '0.7')\n",
    "\n",
    "# Print window size for easy examination of choices\n",
    "ax.text(50, -1.8, f\"Window: {window} words\")\n",
    "\n",
    "ax.plot(times, valences, 'bo-', label = 'Othello')\n",
    "\n",
    "ax.set_xlim(0, 6400)\n",
    "ax.set_ylim(-2, 2.5)\n",
    "ax.legend(loc = 'best', frameon = False, fontsize = my_fontsize)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**That is how we confirm it is a tragedy!** \n",
    "\n",
    "The question, however, is: Was it a tragedy for everyone?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:00:38.723551Z",
     "start_time": "2023-02-12T22:00:38.672132Z"
    }
   },
   "outputs": [],
   "source": [
    "iago_lines = get_character_lines('IAGO', othello_play)\n",
    "\n",
    "print(len(iago_lines))\n",
    "print()\n",
    "\n",
    "iago_words = extract_words_from_lines('Iago', iago_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:00:42.675045Z",
     "start_time": "2023-02-12T22:00:42.511460Z"
    }
   },
   "outputs": [],
   "source": [
    "times = []\n",
    "valences = []\n",
    "corpus = iago_words\n",
    "step = 50\n",
    "window = 500 \n",
    "\n",
    "for i in range(0, len(corpus)-window, step): \n",
    "    temp_corpus = corpus[i:i+int(window / 2)]\n",
    "    count = 0\n",
    "    valence_t = 0\n",
    "    for word in temp_corpus:\n",
    "        if word in valence_dict.keys():\n",
    "            count += 1\n",
    "            valence_t += valence_dict[word]\n",
    "         \n",
    "    if count > 0:\n",
    "        times.append(i + int(window / 2))\n",
    "        valences.append(valence_t / count)\n",
    "        \n",
    "fig = plt.figure( figsize = (6, 4) )\n",
    "ax = fig.add_subplot( 111 )\n",
    "half_frame(ax, 'Word count', 'Emotional valence', font_size = my_fontsize)\n",
    "# Guide to the eye\n",
    "ax.plot([0, 6500], [0, 0], 'k--', lw = 2)\n",
    "ax.fill_between([0, 6500], -2, color = '0.7')\n",
    "\n",
    "ax.text(50, -1.8, f\"Window: {window} words\")\n",
    "\n",
    "ax.plot(times, valences, 'ro-', label = 'Iago')\n",
    "\n",
    "ax.set_xlim(0, 6400)\n",
    "ax.set_ylim(-2, 2.5)\n",
    "ax.legend(loc = 'best', frameon = False, fontsize = my_fontsize)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iago was clearly offended by Othello's happiness at the beginning of the play, don't you think? \n",
    "\n",
    "It might be time to actually to recall [Othello's story](https://en.wikipedia.org/wiki/Othello)...\n",
    "\n",
    "Not bad, ah?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "If I still need to give you exercises, instead of you thinking about something that you would like to do, then I am not doing my job properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:new_base] *",
   "language": "python",
   "name": "conda-env-new_base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "218.567px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
