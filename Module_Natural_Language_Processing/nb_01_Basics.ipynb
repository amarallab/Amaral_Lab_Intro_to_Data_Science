{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synopsis\n",
    "\n",
    "Unstructured text is one of the most plentiful sources of data in many disciplines. However, because this data is unstructured (meaning that it isn't organized nicely into an excel spreadsheet) even basic analysis can be a bit more involved than with other data. In this unit we will go over the basics of textual analysis and cover:\n",
    "\n",
    "* Techniques for **parsing** large-scale text\n",
    "* Basic **bag of words** analysis\n",
    "* Examining **distributions** of word usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-17T20:28:44.712419Z",
     "start_time": "2022-10-17T20:28:44.218474Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from colorama import Back, Fore, Style\n",
    "from pathlib import Path\n",
    "from sys import path\n",
    "\n",
    "path.append('../My_libraries')\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T19:26:25.566907Z",
     "start_time": "2022-09-24T19:26:25.537607Z"
    }
   },
   "outputs": [],
   "source": [
    "my_fontsize = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-17T20:28:56.633153Z",
     "start_time": "2022-10-17T20:28:56.602390Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from random import random\n",
    "from string import punctuation, whitespace\n",
    "\n",
    "from My_libraries.my_stats import half_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text as data\n",
    "\n",
    "Whether it's extracting numerical data from text, or dealing with text directly, the ability to manipulate text in the form of strings is essential for any number of data science projects. More importantly, analyzing text allows for quantitative analysis in a number of areas that would be prohibitive otherwise.\n",
    "\n",
    "Over a decade ago, Google convinced librarians around the world to scan their books for the [Google Books Project](https://www.newyorker.com/business/currency/what-ever-happened-to-google-books). (At the time, people were still buying into their *Do no harm* bullshit $-$ the [Wikipedia page](https://en.wikipedia.org/wiki/Google_Books) provides a less wide-eyed version).  \n",
    "\n",
    "While Google intentions were far from altruistic, the scanning and digitization ended up creating an exciting resource that has enabled all sorts of previously impossible analyses. For example [Michel et al.](https://www.science.org/doi/10.1126/science.1199644) studied the changes in occurrences of specific words or groups of words in books over time:\n",
    "\n",
    "<img src = \"Images/electronic_book_use.png\" width = 600>\n",
    "\n",
    "\n",
    "Quantitative textual analysis makes the task of longitudinal analysis or simply large-scale text possible. However, one important point that I want to impress upon you is that **textual analysis is not nearly as simple as it seems**.  Teaching computers how to perform tasks that are innately easy to you can be quite challenging. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data\n",
    "\n",
    "While the Google's motivation was problematic, a competing effort $-$ [Project Gutenberg](http://www.gutenberg.org) $-$ was digitizing thousands of post-copyright books and making them freely available to all in numerous formats.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src = 'Images/qPSwl88-_400x400.png' width = 80>\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src = 'Images/gutenberg_twain.png' width = 500>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "Luckily for us, this includes the complete works of William Shakespeare which we've pre-downloaded for you.\n",
    "\n",
    "<img src = 'Images/gutenberg_shakespeare.png' width = 600>\n",
    "\n",
    "\n",
    "For data processing in a computer, the best format is typically **plain text**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, **ALWAYS LOOK AT YOUR DATA**. \n",
    "\n",
    "<img src = 'Images/complete_works.png' width = 600>\n",
    "\n",
    "\n",
    "\n",
    "Now is the time to open [Shakespeare.txt](Data/Shakespeare.txt).\n",
    "\n",
    "**So, what questions do you want to be able to answer in order to start working?**\n",
    "\n",
    "> 1. How are different plays separated from one another?\n",
    ">\n",
    "> 2. How is dialogue formatted?\n",
    ">\n",
    "> 3. What extraneous information might we want to ignore?\n",
    ">\n",
    "> 4. How \"well behaved\" is our dataset? (i.e. is the formatting general or unique for different plays?)\n",
    "\n",
    "We will need the answers to all those questions in order to be able to write code to analyze the text. \n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "But, first, let's read the file...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T19:28:20.503967Z",
     "start_time": "2022-09-24T19:28:20.451715Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(Path.cwd() / 'Data' / 'Shakespeare.txt', \n",
    "          'r', encoding= 'UTF-8') as file_in:\n",
    "    complete_works = file_in.readlines()\n",
    "    \n",
    "print(len(complete_works))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T19:28:41.230971Z",
     "start_time": "2022-09-24T19:28:41.201101Z"
    }
   },
   "outputs": [],
   "source": [
    "for line in complete_works[:40]:\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What can we do with this text?\n",
    "\n",
    "First of all, remember that the computer is not an English major.  \n",
    "\n",
    "However, the computer is able to complete long repetitive actions without error or lack of concentration.  So, whatever we can think involving counting, assigning, or comparing, we can do.\n",
    "\n",
    "Even these simple analyses can be quite revealing.  For example, do you know that instructor evaluations tend to use different words to describe the teaching of men and women? Do you know that letters of recommendation also tend to use different terms for describing the skills and potential of men and women? Or that different ethnic groups are described using different terms?\n",
    "\n",
    "Second, the computer is not an English major, but you may very well be one.  For this reason you can instruct the computer on what to do that could be of interest to an English major.\n",
    "\n",
    "But before we do any of that, it is useful to have a little refresher on `string` parsing. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `String` parsing refresher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T19:29:10.306649Z",
     "start_time": "2022-09-24T19:29:10.273074Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(Path.cwd() / 'Data' / 'spoiler_alert.txt', \n",
    "          'r', encoding= 'UTF-8') as file_in:\n",
    "    spoiler_alert = file_in.readlines()\n",
    "    \n",
    "print(len(spoiler_alert))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's iterate through the lines to see what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T19:30:02.184049Z",
     "start_time": "2022-09-24T19:30:02.152947Z"
    }
   },
   "outputs": [],
   "source": [
    "print(spoiler_alert)\n",
    "print()\n",
    "\n",
    "for line in spoiler_alert:\n",
    "    print(f\"-- {line}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing white spaces at start and end of lines\n",
    "\n",
    "When we print line by line there is a lot of empty lines. This is due to an invisible character: `\\n` aka the *new line character*.\n",
    "\n",
    "Usually, it is helpful to get rid of white space that helps humans read but serves no purpose for computers. As you might recall, we can easily strip a `string` of those things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T19:30:27.290589Z",
     "start_time": "2022-09-24T19:30:27.261222Z"
    }
   },
   "outputs": [],
   "source": [
    "for line in spoiler_alert:\n",
    "    print(f\"-- {line.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three things to notice.\n",
    "\n",
    "First, the extra empty lines have disappeared.\n",
    "\n",
    "Second, actual empty lines did not, and neither did white spaces within a line.\n",
    "\n",
    "Third, we have not modified our strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T19:30:39.823959Z",
     "start_time": "2022-09-24T19:30:39.794631Z"
    }
   },
   "outputs": [],
   "source": [
    "spoiler_alert[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding line numbers\n",
    "\n",
    "Using `enumerate`, we can easily get line number when we print. \n",
    "\n",
    "This is particularly helpful when we are trying to **slice** the `list` of line in order to get to what we want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T19:31:55.067695Z",
     "start_time": "2022-09-24T19:31:55.034613Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, line in enumerate(spoiler_alert):\n",
    "    print(f\"{i:>5} -- {line.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for specific text in a line\n",
    "\n",
    "Many times, you are interested in pulling certain lines for the entire text.  Maybe they contain a keyword of interest to you... or maybe they are spoken by a certain character... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T15:04:29.225118Z",
     "start_time": "2022-09-13T15:04:29.196748Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, line in enumerate(spoiler_alert):\n",
    "    if 'the' in line:\n",
    "        print(f\"{i:>4} -- {line.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why aren't lines 1 (\"The potent poison quite o'ercrows my spirit.\") or 3 (\"But I do prophesy th' election lights\") printed?\n",
    "\n",
    "For one, **capitalization matters!**\n",
    "\n",
    "For another, we are not **picking up contractions**.  (I'm assuming th' is a contraction of the).\n",
    "\n",
    "Let's address capitalization first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T19:38:34.151876Z",
     "start_time": "2022-09-24T19:38:34.117510Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make everything lower case\n",
    "#\n",
    "for i, line in enumerate(spoiler_alert):\n",
    "    if 'the' in line.lower():\n",
    "        print(f\"{i:>4} -- {line.strip()}\")\n",
    "        \n",
    "print()\n",
    "\n",
    "# Make everything upper case\n",
    "#\n",
    "for i, line in enumerate(spoiler_alert):\n",
    "    if 'THE' in line.upper():\n",
    "        print(f\"{i:>4} -- {line.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "Is this the only way to find something in a line? Of course not! \n",
    "\n",
    "\n",
    "The `.find()` method even tells us the character position of the match.\n",
    "\n",
    "Not only does `find` tell us whether the text appears in the line, but also exactly where in the line the text **it appears for the first time**  (indexing from 0). \n",
    "\n",
    "If it doesn't find our search query it will return -1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T19:39:37.605887Z",
     "start_time": "2022-09-24T19:39:37.570567Z"
    }
   },
   "outputs": [],
   "source": [
    "test_string = 'the thesaurus'\n",
    "first_index = test_string.find('the ')\n",
    "print(first_index)\n",
    "print(test_string[first_index+1 :].find('the '))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make this code a little more general..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T15:43:50.905486Z",
     "start_time": "2022-09-13T15:43:50.876154Z"
    }
   },
   "outputs": [],
   "source": [
    "pattern = 'the'\n",
    "\n",
    "for i, line in enumerate(spoiler_alert):\n",
    "    first_index = line.lower().find( pattern )\n",
    "    if first_index != -1:\n",
    "        print(f\"{i:>4} -- {line.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, it is helpful to see the slice of a string near a certain pattern.\n",
    "\n",
    "Choose a number of characters `step` to the left and to the right of the pattern and print the corresponding slice of a line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T19:42:36.718845Z",
     "start_time": "2022-09-24T19:42:36.686418Z"
    }
   },
   "outputs": [],
   "source": [
    "step = 5\n",
    "pattern = 'the'\n",
    "pat_length = len(pattern)\n",
    "\n",
    "for i, line in enumerate(spoiler_alert):\n",
    "    first_index = line.lower().find( pattern )\n",
    "    if first_index != -1:\n",
    "        i_start = max(0,first_index - step)\n",
    "        i_end = first_index + pat_length + step\n",
    "        print(f\"{i:>4} -- ...{line[i_start: i_end]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "So, capitalization is taken care of. What about contractions?\n",
    "\n",
    "Let's assume that **th'** is always a contraction of **the**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T19:42:53.979473Z",
     "start_time": "2022-09-24T19:42:53.940531Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, line in enumerate(spoiler_alert):\n",
    "    if 'the' in line.lower() or \"th'\" in line.lower():\n",
    "        print(f\"{i:>4} -- {line.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Finding characters in lines can be used for many purposes.  One of them is to select **slices** of a `string`.\n",
    "\n",
    "As an example, assume that we want to break the text into sentences.\n",
    "\n",
    "Sentences will be ended by periods, exclamation marks or question marks.  So go ahead and break `spoiler_alert` into sentences.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T16:23:08.066500Z",
     "start_time": "2022-09-13T16:23:08.033030Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences = [] # To store all sentences identified\n",
    "\n",
    "end_sentence = ['.', '!', '?'] # Possible ends of sentences\n",
    "  \n",
    "new_sentence = ''  # Start every new sentence with an empty string\n",
    "\n",
    "# Be aware that a sentence may end in the middle of a line \n",
    "#\n",
    "for i, line in enumerate(spoiler_alert):\n",
    "    print(f\"{i:>4} -- {line.strip()}\")\n",
    "\n",
    "    # Your code here\n",
    "    \n",
    "    \n",
    "print(sentences)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `String` splitting refresher\n",
    "\n",
    "Lines and sentences are useful ways of splitting text. However, in many situations we want to be looking at individual words or, more accurately, what we tell the computer constitutes a word!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T16:16:46.248940Z",
     "start_time": "2022-09-13T16:16:46.218451Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, line in enumerate(spoiler_alert):\n",
    "    print(f\"{i:>4} -- {line.strip().split()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad, ah?\n",
    "\n",
    "The default option for `.strip()` and `'split()` acts on `whitespace`, which we can `import` from the `string` package.  \n",
    "\n",
    "As you can see, it does an excellent job of breaking a line into words.\n",
    "\n",
    "You will notice, however, that some words have some punctuation attached at the end.\n",
    "\n",
    "We will take care of it easily enough and, in one fell swoop, remove the pesky punctuation.  To accomplish this, we will use another `import` from the `string` package $-$ `punctuation`.\n",
    "\n",
    "It comprises the characters: \n",
    "\n",
    "> ! \" # $ % & ' ( ) * + , - . / : ; < = > ? @ [ \\ ] ^ _ ` { | } ~\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T19:48:01.179156Z",
     "start_time": "2022-09-24T19:48:01.145895Z"
    }
   },
   "outputs": [],
   "source": [
    "all_the_words = []  # This is where we will store our list of words\n",
    "\n",
    "for i, line in enumerate(spoiler_alert):\n",
    "    line_words = line.strip().split()\n",
    "    print(f\"{i:>4} -- {line_words}\")\n",
    "    \n",
    "    for word in line_words:\n",
    "        print(f\"\\t{word.rstrip(punctuation)}\")\n",
    "        all_the_words.append(word.rstrip(punctuation))\n",
    "\n",
    "print(len(all_the_words))\n",
    "print(all_the_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "Now imagine that we want to count how frequently each words appears (for those words that appear at least once, that is).  Then we must account for the fact that capitalization does not change the word.  That is,  *The* and *the* are the same word.\n",
    "\n",
    "**You know how to take care of this, right?**\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T16:19:37.640952Z",
     "start_time": "2022-09-13T16:19:37.608672Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_the_words = [] \n",
    "\n",
    "for i, line in enumerate(spoiler_alert):\n",
    "    line_words = line.strip().split()\n",
    "    print(f\"{i:>4} -- {line_words}\")\n",
    "    \n",
    "    for word in line_words:\n",
    "#         print(f\"\\t{word.rstrip(punctuation)}\")\n",
    "        all_the_words.append(word.rstrip(punctuation).lower())\n",
    "        \n",
    "Counter(all_the_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Othello is so self-centered. It is all about **I** with him.\n",
    "\n",
    "Alright, we know you are dying. Get over it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to the Complete Works\n",
    "\n",
    "Now that you are refreshed, we can get back to the `complete_works`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T19:54:27.197937Z",
     "start_time": "2022-09-24T19:54:27.166007Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, line in enumerate(complete_works[:30]):\n",
    "    print(f\"{i:>4} -- {line.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "Unfortunately, consistency is far from perfect in how the plays are formatted.  This means that our code to retrieve the different plays is somewhat clunky.\n",
    "\n",
    "I first noticed that a prior to the start of a play, there is one of the copyright statements:\n",
    "\n",
    "> <<THIS ELECTRONIC VERSION OF THE COMPLETE WORKS OF WILLIAM\n",
    "SHAKESPEARE IS COPYRIGHT 1990-1993 BY WORLD LIBRARY, INC., AND IS\n",
    "PROVIDED BY PROJECT GUTENBERG ETEXT OF ILLINOIS BENEDICTINE COLLEGE\n",
    "WITH PERMISSION.  ELECTRONIC AND MACHINE READABLE COPIES MAY BE\n",
    "DISTRIBUTED SO LONG AS SUCH COPIES (1) ARE FOR YOUR OR OTHERS\n",
    "PERSONAL USE ONLY, AND (2) ARE NOT DISTRIBUTED OR USED\n",
    "COMMERCIALLY.  PROHIBITED COMMERCIAL DISTRIBUTION INCLUDES BY ANY\n",
    "SERVICE THAT CHARGES FOR DOWNLOAD TIME OR FOR MEMBERSHIP.>>\n",
    "\n",
    "I thus use the first line of that statement as an indicator pattern. **I use a Boolean variable to signal that I may be within a stretch of lines with a play inside.**\n",
    "    \n",
    "Next, I noticed that plays start with the year of publication (or first performance...).  This is a numeric string, giving me another pattern to match.\n",
    "    \n",
    "If, within a few lines after finding a year, I find a line all in upper case, then I know that this is a play title. **I use a Boolean variable to signal that I have now found a play.**\n",
    "    \n",
    "I assume I remain inside the play until I find the pattern *THE END*.  At this point, I switch my Boolean variables to `False`.\n",
    "    \n",
    "The output of this code is to create a dictionary storing the names of the plays, their year of publication, and their start and end lines within the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T15:16:50.245881Z",
     "start_time": "2022-09-26T15:16:50.166133Z"
    }
   },
   "outputs": [],
   "source": [
    "elect_pattern = '<<THIS ELECTRONIC VERSION OF THE COMPLETE WORKS OF WILLIAM'\n",
    "\n",
    "plays = {}\n",
    "inside_flag = False\n",
    "found_play = False\n",
    "\n",
    "for i, line in enumerate(complete_works):\n",
    "    if not inside_flag and line.strip() == elect_pattern:\n",
    "        inside_flag = True\n",
    "        print(i)\n",
    "        continue\n",
    "        \n",
    "    if inside_flag and line.strip().isnumeric():\n",
    "#         print(counter, i, complete_works[i].strip())\n",
    "#         print(complete_works[i+2].strip())\n",
    "#         print(i, inside_flag, found_play)\n",
    "        if ( complete_works[i+2].upper() == complete_works[i+2] or\n",
    "             complete_works[i+3].upper() == complete_works[i+3] or \n",
    "             complete_works[i+6].upper() == complete_works[i+6]):\n",
    "            found_play = True\n",
    "            year_play = int( line.strip() )\n",
    "            \n",
    "            if complete_works[i+2].strip() == '':\n",
    "                if complete_works[i+3].strip() == '':\n",
    "                    title_play = complete_works[i+6].strip()\n",
    "                    plays[title_play] = [year_play, i+6]\n",
    "                else:\n",
    "                    title_play = complete_works[i+3].strip()\n",
    "                    plays[title_play] = [year_play, i+3]\n",
    "            else:    \n",
    "                title_play = complete_works[i+2].strip()\n",
    "                plays[title_play] = [year_play, i+2]\n",
    "        continue\n",
    "            \n",
    "    if found_play and line.strip() == 'THE END':\n",
    "        plays[title_play].append(i)\n",
    "        print(title_play, plays[title_play])\n",
    "        found_play = False\n",
    "        inside_flag = False\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T15:16:59.973972Z",
     "start_time": "2022-09-26T15:16:59.940185Z"
    }
   },
   "outputs": [],
   "source": [
    "# And here we have it\n",
    "\n",
    "plays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We will be focusing on Othello, or, more precisely *THE TRAGEDY OF OTHELLO, MOOR OF VENICE*\n",
    "\n",
    "We have all the information to select this play in our `plays` dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T15:21:48.620557Z",
     "start_time": "2022-09-26T15:21:48.588701Z"
    }
   },
   "outputs": [],
   "source": [
    "title = 'THE TRAGEDY OF OTHELLO, MOOR OF VENICE'\n",
    "print(title)\n",
    "print(plays[title])\n",
    "\n",
    "print(f\"\\nThis play was published in {plays[title][0]}.\\n\")\n",
    "line_start = plays[title][1]\n",
    "line_end = plays[title][2]\n",
    "\n",
    "the_play = complete_works[line_start:line_end+1]\n",
    "\n",
    "print(f\"It takes {len(the_play)} lines in the file.\\n\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, **always** make sure you really have what you _think_ you have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T15:21:59.398554Z",
     "start_time": "2022-09-26T15:21:59.370674Z"
    }
   },
   "outputs": [],
   "source": [
    "print(the_play[:40])\n",
    "print()\n",
    "\n",
    "print(the_play[-40:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the character names\n",
    "\n",
    "\n",
    "Great! We have the play!\n",
    "\n",
    "You will also notice that after **Dramatis Personae**, there is a list of characters in the play.\n",
    "\n",
    "And it all ends with the copyright statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T15:23:20.921907Z",
     "start_time": "2022-09-26T15:23:20.892878Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_pattern = 'Dramatis Personae'\n",
    "end_pattern = elect_pattern\n",
    "\n",
    "# Get lines with listing of characters\n",
    "#\n",
    "found_personae = False\n",
    "for i, line in enumerate(the_play):\n",
    "    if start_pattern in line:\n",
    "        start_line = i + 1\n",
    "        continue \n",
    "        \n",
    "    if end_pattern in line:\n",
    "        end_line = i\n",
    "        break\n",
    "        \n",
    "personae_text = the_play[start_line: end_line]\n",
    "print(personae_text)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "**NOTICE THAT THE MANNER IN WHICH THIS INFORMATION IS FORMATED IS NOT IDENTICAL FOR ALL PLAYS.**\n",
    "\n",
    "We want to get the characters' names and descriptions.  **What would be a good data structure for those data?**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T15:34:15.572412Z",
     "start_time": "2022-09-26T15:34:15.540257Z"
    }
   },
   "outputs": [],
   "source": [
    "personae = {}  ## Yes, a dictionary!!!\n",
    "\n",
    "for i, line in enumerate(personae_text):\n",
    "    if line == '\\n':\n",
    "        continue\n",
    "\n",
    "    print(f\"{i:>3} -- {line.strip()}\")\n",
    "    \n",
    "    # Split by comma, take first item if is all caps, \n",
    "    # join the rest\n",
    "    \n",
    "    items = line.strip().split(',')\n",
    "#     print(items)\n",
    "    \n",
    "    if items[0].upper() == items[0]:\n",
    "        name = items[0].strip()\n",
    "        description = ','.join(items[1:]).strip()\n",
    "        personae[name] = description\n",
    "#         print(name, '--', description)\n",
    "\n",
    "print()\n",
    "personae\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the lines from a specific character\n",
    "\n",
    "Below, you can see the beginning of ACT I. \n",
    "\n",
    "You will notice a nice pattern to how lines are assigned to a character\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T15:36:04.197079Z",
     "start_time": "2022-09-26T15:36:04.167212Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "snippet = the_play_othello[40:53]\n",
    "\n",
    "print(Fore.RED, f\"   --12345678901234567890\", Style.RESET_ALL)\n",
    "for i, line in enumerate(snippet):\n",
    "    print(f\"{i:>4}--{line.rstrip()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The start of a character's line begins with the two spaces followed by the character's name capitalized and a period.\n",
    "\n",
    "All the following lines that start with four spaces are assigned to that character. And then, the lines of a new character start.\n",
    "\n",
    "```\n",
    "\"  CHARACTER. blahblahblah\n",
    "     blahblahblah\"\n",
    "```\n",
    "\n",
    "We can work with that, right?\n",
    "\n",
    "Start by getting RODERIGO's lines from the `snippet`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T17:00:50.082632Z",
     "start_time": "2022-09-13T17:00:50.050802Z"
    }
   },
   "outputs": [],
   "source": [
    "character = 'RODERIGO'\n",
    "character_lines = []\n",
    "\n",
    "found_lines = False\n",
    "for i, line in enumerate(snippet):\n",
    "    if line.split('.')[0] == '  ' + character:\n",
    "        print(f\"{i:>4}--{line.rstrip()}\")\n",
    "        found_lines = True\n",
    "        character_lines.append(line)\n",
    "        continue\n",
    "    \n",
    "    if found_lines:\n",
    "        if line[:4] == '    ':\n",
    "            print(f\"{i:>4}--{line.rstrip()}\")\n",
    "            character_lines.append(line)\n",
    "        else:\n",
    "            found_lines = False\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and modify the code to read the lines from IAGO in the snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting and working a character's lines\n",
    "\n",
    "\n",
    "Let's start by writing a function that reads and stores a character's lines given the lines in a play and the character's name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T15:38:14.841403Z",
     "start_time": "2022-09-26T15:38:14.807675Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_character_lines( character, play_lines ):\n",
    "    \"\"\"\n",
    "    This function takes the name of a character and the lines from the play\n",
    "    extracted from GP's Complete Works of William Shakespeare and returns\n",
    "    a list with all the lines from that character in the play\n",
    "    \n",
    "    inputs:\n",
    "        character -- str\n",
    "        play_lines -- list of str\n",
    "        \n",
    "    returns:\n",
    "        character_lines -- list of str\n",
    "    \"\"\"\n",
    "    character_lines = []\n",
    "    character = character.upper()\n",
    "    \n",
    "    start_string = ' '*2 + character\n",
    "    continuation_string = ' '*4\n",
    "    \n",
    "    found_lines = False\n",
    "    for i, line in enumerate(play_lines):\n",
    "        if line.split('.')[0] == start_string:\n",
    "            found_lines = True\n",
    "            character_lines.append(line.replace(start_string+ '.', '').strip())\n",
    "            continue\n",
    "\n",
    "        if found_lines:\n",
    "            if line[:len(continuation_string)] == continuation_string:\n",
    "                character_lines.append(line.strip())\n",
    "            else:\n",
    "                found_lines = False\n",
    "                continue \n",
    "    \n",
    "    return character_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T15:38:16.969374Z",
     "start_time": "2022-09-26T15:38:16.939918Z"
    }
   },
   "outputs": [],
   "source": [
    "othello_lines = read_character_lines('othello', the_play)\n",
    "\n",
    "print(len(othello_lines))\n",
    "print(othello_lines[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T15:38:41.633139Z",
     "start_time": "2022-09-26T15:38:41.601059Z"
    }
   },
   "outputs": [],
   "source": [
    "iago_lines = read_character_lines('iago', the_play)\n",
    "print(len(iago_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T15:39:02.517593Z",
     "start_time": "2022-09-26T15:39:02.487000Z"
    }
   },
   "outputs": [],
   "source": [
    "desdemona_lines = read_character_lines('desdemona', the_play)\n",
    "print(len(desdemona_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T15:39:12.071105Z",
     "start_time": "2022-09-26T15:39:12.038969Z"
    }
   },
   "outputs": [],
   "source": [
    "brabantio_lines = read_character_lines('brabantio', the_play)\n",
    "print(len(brabantio_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words approaches\n",
    "\n",
    "Many NLP techniques make use of the so-called **bag of words** model. \n",
    "\n",
    "The idea is that you just get the words in some text and completely forget about their order and restrict yourselves to things that can be counted.\n",
    "\n",
    "In order to move forward with this approach, it is helpful to write a function that given a list of lines breaks them into list of words.\n",
    "\n",
    "That is your mission for the next few minutes, if you choose to take it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T18:45:23.763412Z",
     "start_time": "2022-09-13T18:45:23.733738Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_words_from_lines( character_lines ):\n",
    "    \"\"\"\n",
    "    This function takes a list with all the lines from a character \n",
    "    in the play and returns a list of words\n",
    "    \n",
    "    inputs:\n",
    "        character_lines -- list of str\n",
    "        \n",
    "    returns:\n",
    "        character_words -- list of str\n",
    "    \"\"\"\n",
    "    character_words = []\n",
    "        \n",
    "    return character_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's get the words spoken by Othello and use the `Counter` to get some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T15:43:08.846134Z",
     "start_time": "2022-09-26T15:43:08.783393Z"
    }
   },
   "outputs": [],
   "source": [
    "othello_words = extract_words_from_lines(othello_lines)\n",
    "\n",
    "print(f\"Othello's lines comprise {len(othello_words)} words.\\n\")\n",
    "print(f\"Othello's lines comprise {len(set(othello_words))} \"\n",
    "      f\"unique words.\\n\")\n",
    "\n",
    "othello_counter = Counter(othello_words)\n",
    "\n",
    "print(len(othello_words)/ len(set(othello_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**That means that each unique word is occurs an average of about 3.8 times.**\n",
    "\n",
    "How good is this average a description of common words?\n",
    "\n",
    "You can then get his most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T18:47:31.637642Z",
     "start_time": "2022-09-13T18:47:31.605658Z"
    }
   },
   "outputs": [],
   "source": [
    "othello_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interesting how the most common words appear about 50 times more frequently than one would expect**.\n",
    "\n",
    "Some of those are clearly the usual suspects: *the*, *and*, *to*, *of*, *a*.\n",
    "\n",
    "Not so typically, are *I* and *me*.\n",
    "\n",
    "As we know, there is no **I** in **team**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T18:49:09.827892Z",
     "start_time": "2022-09-13T18:49:09.795929Z"
    }
   },
   "outputs": [],
   "source": [
    "print(othello_counter['we'])\n",
    "print(othello_counter['team'])\n",
    "print(othello_counter['othello'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the most common words appear so frequently, the least common words must appear only a single time.\n",
    "\n",
    "**Moreover, there should be many of those single occurrence words**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T18:49:25.611187Z",
     "start_time": "2022-09-13T18:49:25.580431Z"
    }
   },
   "outputs": [],
   "source": [
    "othello_counter.most_common()[-20:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T18:49:43.055961Z",
     "start_time": "2022-09-13T18:49:43.027236Z"
    }
   },
   "outputs": [],
   "source": [
    "othello_counter.most_common()[-1020:-1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, over a thousand words appear only once.\n",
    "\n",
    "This seems like a very strange distribution doesn't it?  There are a lot of words with very low probability of occurring and then a few with a high probability of occurring.\n",
    "\n",
    "It is almost as if there was a country where most of the population was only 1 foot tall but then there where a couple 200 feet tall giants walking around.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zipf's law\n",
    "\n",
    "Because this distribution is so strange, we will look at it in a little more detail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T18:51:12.162021Z",
     "start_time": "2022-09-13T18:51:12.131496Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get frequency of words from Counter object\n",
    "#\n",
    "counts = list( dict(othello_counter).values() )\n",
    "\n",
    "print(counts[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T18:52:19.059518Z",
     "start_time": "2022-09-13T18:52:18.889891Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize = (6, 4) )\n",
    "ax = fig.add_subplot( 111 )\n",
    "half_frame(ax, 'Number of occurrences', 'Frequency', font_size = my_fontsize)\n",
    "\n",
    "ax.hist( counts, bins = np.arange(-0.5, 250.5, 10), \n",
    "         align = 'mid', rwidth = 0.9, label = 'Othello')\n",
    "\n",
    "ax.legend(loc = 'best', frameon = False, fontsize = my_fontsize)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not the most enlightening plot...\n",
    "\n",
    "Setting a logarithmic scale on the y-axis will help "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T18:53:00.322012Z",
     "start_time": "2022-09-13T18:52:59.914640Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize = (6, 4) )\n",
    "ax = fig.add_subplot( 111 )\n",
    "half_frame(ax, 'Number of occurrences', 'Frequency', font_size = my_fontsize)\n",
    "\n",
    "ax.hist( counts, bins = np.arange(-0.5, 250.5, 10), \n",
    "         align = 'mid', rwidth = 0.9, label = 'Othello' )\n",
    "\n",
    "ax.semilogy()\n",
    "ax.legend(loc = 'best', frameon = False, fontsize = my_fontsize)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better, but not yet great. Let's make the x-axis have a logarithmic scale too..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T18:53:40.631448Z",
     "start_time": "2022-09-13T18:53:40.263751Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize = (6, 4) )\n",
    "ax = fig.add_subplot( 111 )\n",
    "half_frame(ax, 'Number of occurrences', 'Frequency', font_size = my_fontsize)\n",
    "\n",
    "ax.hist( counts, bins = np.arange(0.5, 250.5, 10), \n",
    "         align = 'mid', rwidth = 0.9, label = 'Othello' )\n",
    "\n",
    "ax.loglog()\n",
    "ax.legend(loc = 'best', frameon = False, fontsize = my_fontsize)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not the best plot, but you can kind of see how the frequency decays as a straight like in this double **logarithmic plot**.\n",
    "\n",
    "Such a pattern is indicative of a power-law decay\n",
    "\n",
    "> $P(k) \\propto k^{-\\alpha}$\n",
    "\n",
    "In the context of human languages this is called evidence for [Zipf's law](https://en.wikipedia.org/wiki/Zipf%27s_law). \n",
    "\n",
    "Because the support of the data is so large, the frequency plot gets to be quite noisy for large values of $k$.  \n",
    "\n",
    "For this reason, it is typically best to plot the survival function instead of the frequency.\n",
    "\n",
    "The survival function shows the number of values larger than $k$.\n",
    "\n",
    "The next cell shows how this is calculated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T18:54:28.180195Z",
     "start_time": "2022-09-13T18:54:27.780326Z"
    }
   },
   "outputs": [],
   "source": [
    "k_values = []\n",
    "survival_function = []\n",
    "\n",
    "n = len(counts)\n",
    "for k in sorted(counts):\n",
    "    if k not in k_values:\n",
    "        k_values.append(k)\n",
    "        survival_function.append(n)\n",
    "        n -= 1\n",
    "    else:\n",
    "        n -= 1\n",
    "        \n",
    "fig = plt.figure( figsize = (6, 4) )\n",
    "ax = fig.add_subplot( 111 )\n",
    "half_frame(ax, 'Number of occurrences', 'Survival function', font_size = my_fontsize)\n",
    "ax.loglog()\n",
    "\n",
    "# Add a line as a guide to the eye\n",
    "ax.plot([1, 200], [1400, 3.8], 'b-', lw = 6, alpha = 0.3)\n",
    "\n",
    "ax.plot( k_values, survival_function, 'r-', lw = 2, label = 'Othello' )\n",
    "\n",
    "ax.legend(loc = 'best', frameon = False, fontsize = my_fontsize)\n",
    "\n",
    "plt.tight_layout()   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text entropy\n",
    "\n",
    "Bag of words approaches allow for easy calculation of many things. Above, we considered three quantities: number of words, size of vocabulary (aka, number of unique words), and distribution of word frequencies.\n",
    "\n",
    "While is seems hard to compare distributions, the fact is that typical corpus generated from human language obey Zifp's law.  Moreover, the exponent in Zipf's law is related to measures of concentration. The smaller the value of the exponent $\\alpha$ the more concentrated the speech is on a few words. Thus, the distribution also gives us a single number with which to compare characters.\n",
    "\n",
    "Another way to measure someone's speech is by using **entropy**. [Entropy](https://en.wikipedia.org/wiki/Entropy) is a concept introduced in the study of heat. It measures disorder and in a sense tells us how hard to predict something is.\n",
    "\n",
    "We are all much more predictable then we like to think. That is the reason why we are so easy to make fun of.  For instance, I seem to love the word *essentially*. Or at least that is what my so-called loved ones claim.\n",
    "\n",
    "Entropy has also been introduced in the context of [Information Theory](https://en.wikipedia.org/wiki/Entropy_%28information_theory%29) where it is related to how surprising new information is.  When we listen to speech, every new word uttered brings new information. Sometimes, the amount of new information is close to zero because we already know what is coming\n",
    "\n",
    "> baa baa black sheep\n",
    ">\n",
    "> have you any...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So, how is entropy calculated?**\n",
    "\n",
    "In the context of language, we can say that our speech is composed of words. Each word is an instance of a token (aka, unique word).  We can associate with each token a probability of selection. \n",
    "\n",
    "For example, let's say that our vocabulary has three tokens -- *hello*, *friends*, and *folks* -- and that each token has an associated probability of being selected. Then we can create a speech generator. Yes this is AI!\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T15:23:44.011666Z",
     "start_time": "2022-07-20T15:23:43.979374Z"
    }
   },
   "outputs": [],
   "source": [
    "vocabulary = {'hello': 0.5, 'friends': 0.35, 'folks': 0.15}\n",
    "\n",
    "speech_size = 100\n",
    "speech = []\n",
    "for i in range(speech_size):\n",
    "    x = random()\n",
    "    p = 0\n",
    "    for key in vocabulary:\n",
    "        p += vocabulary[key]\n",
    "        if x < p:\n",
    "            speech.append(key)\n",
    "            break\n",
    "    \n",
    "print(speech)\n",
    "Counter(speech)\n",
    "\n",
    "speech_counter = Counter(speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropy is expressed as a function of the probabilities of the tokens:\n",
    "\n",
    "\n",
    "> $H(X) = -\\sum ~ p_i ~\\log p_i $\n",
    "\n",
    "Where $i$ is the index for a token and $p_i$ is the probability of that token appearing in the text. \n",
    "\n",
    "In our context, the best estimate that we have of the probability of any given token is the ratio of the number of occurrences to the number of words.\n",
    "\n",
    "> $p_i = \\frac{n_i}{N}$\n",
    "\n",
    "So, go ahead and write a function to calculate the entropy of a text given a `Counter` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T15:23:56.217619Z",
     "start_time": "2022-07-20T15:23:56.185471Z"
    }
   },
   "outputs": [],
   "source": [
    "def text_entropy( counter ):\n",
    "    \"\"\"\n",
    "    This function takes a Counter object and returns the entropy of the \n",
    "    underlying text.\n",
    "    \n",
    "    inputs:\n",
    "        counter -- Counter object\n",
    "        \n",
    "    returns:\n",
    "        entropy -- float\n",
    "    \"\"\"\n",
    "    entropy = 0\n",
    "    \n",
    "    # Code here\n",
    "\n",
    "    return entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T15:21:27.285238Z",
     "start_time": "2022-07-20T15:21:27.253581Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"The entropy of the speech generator is \"\n",
    "      f\"{text_entropy(speech_counter):.2f}\\n\")\n",
    "\n",
    "print(\"The entropy of Othello's speech is \"\n",
    "      f\"{text_entropy(othello_counter):.2f}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the entropy scores for the these two forms of speech are quite different.\n",
    "\n",
    "Not surprisingly, Othello's speech has much higher entropy -- that is, is much less predictable.\n",
    "\n",
    "What about the speech of other the characters?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and calculate the speech entropy of other major characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have calculated the properties of the entirety of the lines of a character.  However, it could be that the properties of the speech change in the course of the play.\n",
    "\n",
    "How would you go about doing this?\n",
    "\n",
    "Yes, exactly, calculate the change in properties of the speech of Othello over a set of 1000 consecutive words and plot how other speech properties change across the play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous exercises, you calculated a bunch of numbers.  Sometimes, those numbers appear to be quite different (1.46 *vs.* 8.84). Other times, not so much.\n",
    "\n",
    "How would you be able to estimate the uncertainty in those number?\n",
    "\n",
    "Is it $8.84 \\pm 0.01$ or $8.8 \\pm 1.0$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
