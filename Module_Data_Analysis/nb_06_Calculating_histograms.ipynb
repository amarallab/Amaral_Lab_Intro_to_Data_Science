{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synopsis\n",
    "\n",
    "In this notebook, I will discuss the steps for calculating an informative histogram.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T19:58:10.158443Z",
     "start_time": "2023-01-05T19:58:10.103974Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from colorama import Back, Fore, Style\n",
    "from pathlib import Path\n",
    "from sys import path\n",
    "\n",
    "path.append( str(Path.cwd().parent) )\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T19:58:10.807708Z",
     "start_time": "2023-01-05T19:58:10.758014Z"
    }
   },
   "outputs": [],
   "source": [
    "my_fontsize = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T19:58:11.507312Z",
     "start_time": "2023-01-05T19:58:11.465740Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "from copy import copy\n",
    "\n",
    "from Amaral_libraries.my_stats import half_frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms, frequency plots and so on\n",
    "\n",
    "It is often said that one picture is worth a thousand words. \n",
    "\n",
    "This is particularly true where data is concerned. Descriptive statistics can be useful if data are normal, that is, have a central tendency and are not skewed.  \n",
    "\n",
    "If this is not the case, then descriptive statistics hide much information that may be relevant.\n",
    "\n",
    "Of course, one could list all data values, but that is not typically a helpful solution even if the sample size is not enormous. \n",
    "\n",
    "Consider the following cases where distribution is deeply right-skewed:\n",
    "\n",
    "1. Jeff Bezos (evilness)\n",
    "\n",
    "2. Elon Musk (stupidity)\n",
    "\n",
    "2. Harry Potter (sales)\n",
    "\n",
    "3. Earthquakes (energy)\n",
    "\n",
    "4. Fires (area)\n",
    "\n",
    "5. Population of countries (people)\n",
    "\n",
    "In such cases, we want to be able to construct **histograms**, which are normalized versions of frequency plots. \n",
    "\n",
    "Let us first create some data for playing with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T19:58:15.716416Z",
     "start_time": "2023-01-05T19:58:15.662491Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "samples = []\n",
    "samples.append( stats.poisson.rvs(3, size = n) )\n",
    "\n",
    "samples.append( list(stats.poisson.rvs(1., size = int(n/2))) )\n",
    "samples[-1].extend(list(stats.poisson.rvs(5., size = n - int(n/2))))\n",
    "\n",
    "samples.append( stats.uniform.rvs(0, 6, size = n) )\n",
    "\n",
    "samples.append( list(stats.poisson.rvs(2., size = int(n/2))) )\n",
    "samples[-1].extend(list(stats.poisson.rvs(4., size = n - int(n/2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily write a loop over the different data samples and using different statistical descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T19:58:18.704295Z",
     "start_time": "2023-01-05T19:58:18.655636Z"
    }
   },
   "outputs": [],
   "source": [
    "my_stats = [np.mean, np.median, np.std, stats.skew, stats.kurtosis]\n",
    "stat_names = ['mean', 'median', 'standard deviation', 'skewness', 'kurtosis']\n",
    "\n",
    "j = 3 # change the value of j\n",
    "\n",
    "for i, sample in enumerate(samples):\n",
    "    print(f\"The {stat_names[j]} of sample_{i+1} is {my_stats[j](sample): .2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps for creating a histogram\n",
    "\n",
    "## Determine the dimensionality of your data\n",
    "\n",
    "If the dimensionality is 1 then you are fine. If the dimensionality is 2, you may still be able to create a useful histogram if you have enough data. For all other cases, you can only plot the marginal distributions.\n",
    "\n",
    "## Determine data type and support\n",
    "\n",
    "**What is the type of your data?** Categorical? Integer? Continuous?\n",
    "\n",
    "**What is the support of your data?** Is it all integers greater than 0? All real numbers in [0, 1]? A set of color names?\n",
    "\n",
    "**If your data is continuous**, you will have to define bins for counting the number of events. Next, implement the following steps:\n",
    "\n",
    "1.\tCalculate the sample mean and sample standard deviation.\n",
    "2.\tIf most of the data falls within a few standard deviations from the mean, then you can define your bins to be equal sized and with a width that will depend in a linear fashion with the sample size and the sample standard deviation.\n",
    "3.\tIf that is not the case, then the size of your bins should follow a geometric series.\n",
    "\n",
    "**If your data is categorical or integer**, then the way to proceed depends on the number of distinct values.  If the number is large, then you will also have to define bins for counting number of events. In this case, the bins will be contiguous ranges of integer values or groups of categories (‘European’ for ‘Austrian, ‘Belgian’ and so on, ‘African’ for ‘Algerian’, ‘Beninese’ and so on). If the number is relatively small, then each distinct value goes into your list of possible values.\n",
    "\n",
    "## Determine frequency counts\n",
    "\n",
    "Calculate the number of data points equal to a certain value or falling inside a given bin.\n",
    "\n",
    "## Normalize the frequency counts \n",
    "\n",
    "To obtain a histogram, that is, an estimate of the probability of obtaining a given value for a data point drawn from the same distribution, you divide the frequency count by the product of the sample size and the number of values included in the bin.  \n",
    "\n",
    "> For integer or categorical data, the number of values in a bin is just a count of how many values are in the bin.\n",
    ">\n",
    ">For continuous data, the number of values is the size of the bin. For example:\n",
    ">\n",
    ">> if you divide the interval `[0, 1]` into ten bins, `{[0, 0.1), [0.1, 0.2), …}`, then the size of each bin is 0.1.\n",
    "\n",
    "\n",
    "**NEVER DO THIS!**\n",
    "\n",
    "<img src = 'Images/wh_economic_growth.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A categorical example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T19:58:51.631185Z",
     "start_time": "2023-01-05T19:58:35.000640Z"
    }
   },
   "outputs": [],
   "source": [
    "answers = []\n",
    "n = int( input('Enter sample size:') )\n",
    "\n",
    "for i in range(n):\n",
    "    color = input('Enter eye color:')\n",
    "    answers.append(color.capitalize())\n",
    "\n",
    "print(answers)\n",
    "plt.hist(answers)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our data from before\n",
    "\n",
    "1. All 4 samples considered are 1-dimensional, so we are fine\n",
    "2. The data is continuous in one case but integer in the other cases\n",
    "3. We must determine the support of each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T19:58:58.409619Z",
     "start_time": "2023-01-05T19:58:58.356512Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, sample in enumerate(samples):\n",
    "    print(f\"The minimum of sample_{i+1} is {min(sample): .2f} and \"\n",
    "          f\"the maximum is {max(sample): .2f}\\n\"\n",
    "          f\"The mean is {np.mean(sample): .2f} and the support is \"\n",
    "          f\"{(max(sample)-min(sample)/np.std(sample)): .2f}X \"\n",
    "          f\"the standard deviation.\\n\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "In every case, the support is not too large when compared to the standard deviation\n",
    "\n",
    "### Discrete variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T19:59:02.471529Z",
     "start_time": "2023-01-05T19:59:02.428129Z"
    }
   },
   "outputs": [],
   "source": [
    "colors = ['red', 'blue', 'orange', 'green']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T19:59:03.022812Z",
     "start_time": "2023-01-05T19:59:02.884882Z"
    }
   },
   "outputs": [],
   "source": [
    "j = 1 # do not change value of j\n",
    "sample = samples[j]\n",
    "\n",
    "fig = plt.figure( figsize = (6, 4.5) )\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "my_font_size = 15\n",
    "half_frame(ax, \"k\", \"Probability Mass\", font_size = my_font_size)\n",
    "\n",
    "if type(sample[0]) in [np.int64, np.int32, int]:\n",
    "    k_min = min(sample)\n",
    "    k_max = max(sample)\n",
    "    k_range = range(k_min, k_max + 1)\n",
    "\n",
    "    hist = [0] * len(k_range)\n",
    "    for k in sample:\n",
    "        hist[k-k_min] += 1\n",
    "\n",
    "    hist = np.array(hist) / len(sample)\n",
    "    k_range = np.array(k_range)\n",
    "    \n",
    "    # Calculate and plot histogram\n",
    "    ax.vlines( k_range, 0, hist, color = colors[j], linewidth = 5, alpha = 0.8, \n",
    "               label = f\"sample_{j+1}\")\n",
    "\n",
    "# Format legend\n",
    "ax.legend(loc = (1.0, 0.6), frameon = False, markerscale = 1.8, \n",
    "          fontsize = my_font_size)\n",
    "\n",
    "ax.set_xlim(k_min-1, k_max+1)\n",
    "ax.set_ylim(0, max(hist))\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T19:59:08.033381Z",
     "start_time": "2023-01-05T19:59:07.918042Z"
    }
   },
   "outputs": [],
   "source": [
    "j = 2 # do not change value of j\n",
    "\n",
    "sample = samples[j]\n",
    "x_min = min(sample)\n",
    "x_max = max(sample)\n",
    "\n",
    "n_bins = int((x_max - x_min) / np.std(sample) * np.sqrt(len(sample))/4)\n",
    "# n_bins = 12\n",
    "\n",
    "bin_width = (x_max - x_min) / n_bins\n",
    "\n",
    "x_range = np.arange(x_min, x_max, bin_width)\n",
    "\n",
    "hist = [0]*n_bins\n",
    "for x in sample:\n",
    "    if x < x_max:\n",
    "        k = int((x - x_min) / bin_width)\n",
    "        hist[k] += 1\n",
    "        \n",
    "hist = np.array(hist) / bin_width / len(sample)\n",
    "\n",
    "\n",
    "fig = plt.figure( figsize = (6, 4.5) )\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "my_font_size = 15\n",
    "half_frame(ax, \"x\", \"Probability density\", font_size = my_font_size)\n",
    "\n",
    "ax.vlines(x_range+bin_width/2, 0, hist, color = colors[2], lw = 35,\n",
    "          label = f\"sample_{j+1}\")\n",
    "\n",
    "ax.hlines(1./6., x_min, x_max, color = 'green', lw = 3)\n",
    "ax.set_ylim(0, 0.25)\n",
    "\n",
    "# Format legend\n",
    "ax.legend(loc = (1.0, 0.6), frameon = False, markerscale = 1.8, \n",
    "          fontsize = my_font_size)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When the support is too large\n",
    "\n",
    "Let us now consider the creation of a histogram for data that spans a very broad range of scales, for example, from 0.001 to 1000. In such as situation, **using bins that are equally sized will not produce an informative histogram**.  \n",
    "\n",
    "Either your bins are very small and there are too many of them so there will be no data points for most of them, or you bins are very big and almost all data points will fall in the first bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T19:59:13.291497Z",
     "start_time": "2023-01-05T19:59:13.170403Z"
    }
   },
   "outputs": [],
   "source": [
    "alpha, location, beta = 0.5, 0., 1000\n",
    "sample = stats.gamma.rvs(alpha, location, beta, size = 1000)\n",
    "\n",
    "x_min = min(sample)\n",
    "x_max = max(sample)\n",
    "n_bins = 10 # Few bins\n",
    "# n_bins = 10000 # Lots of bins\n",
    "\n",
    "bin_width = (x_max - x_min) / n_bins\n",
    "x_range = np.arange(x_min, x_max, bin_width)\n",
    "\n",
    "hist = [0]*n_bins\n",
    "for x in sample:\n",
    "    if x < x_max:\n",
    "        k = int((x - x_min) / bin_width)\n",
    "        hist[k] += 1\n",
    "        \n",
    "hist = np.array(hist) / bin_width / len(sample)\n",
    "\n",
    "\n",
    "fig = plt.figure( figsize = (6, 4.5) )\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "my_font_size = 15\n",
    "half_frame(ax1, \"x\", \"Probability density\", font_size = my_font_size)\n",
    "\n",
    "ax1.plot(x_range+bin_width/2, hist, color = colors[2], lw = 2)\n",
    "\n",
    "ax1.set_ylim(0, 0.0012)\n",
    "ax1.set_xlim(0, 6000)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution to this problem is to define bins whose size increases as a geometric series: \n",
    "\n",
    "> $size\\_bin_i = size\\_bin_{i-1} * b ~~~~~ \\Rightarrow ~~~~~size\\_bin_i = b^i$\n",
    "\n",
    "where $b \\gt 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More fun with histograms\n",
    "\n",
    "First, let's check that we have the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T19:59:17.135141Z",
     "start_time": "2023-01-05T19:59:17.076036Z"
    }
   },
   "outputs": [],
   "source": [
    "data_folder = Path.cwd() / 'Data'\n",
    "\n",
    "print(data_folder.exists())\n",
    "print()\n",
    "print(data_folder)\n",
    "print()\n",
    "\n",
    "for file_path in data_folder.glob('*.csv'): \n",
    "    print( file_path )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data and plot frequency plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T19:59:22.356447Z",
     "start_time": "2023-01-05T19:59:22.274568Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = data_folder / 'individual_physical_attributes.csv'\n",
    "with open(file_path, 'r') as file_in:\n",
    "    df = pd.read_csv(file_in)\n",
    "    \n",
    "heights = list( copy(df.Height) )\n",
    "n = 10\n",
    "print(f\"Print first {n} values of data:\\n\\t{heights[:n]}\\n\")\n",
    "\n",
    "h_min = min(heights)\n",
    "h_max = max(heights)\n",
    "print(f\"We have {len(heights)} data points. The maximum is {h_max} and the minimum is {h_min}.\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It all looks mostly ok, except for that little problem that someone is listed as 195 inches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T19:59:25.483243Z",
     "start_time": "2023-01-05T19:59:25.433429Z"
    }
   },
   "outputs": [],
   "source": [
    "195/12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oh, oh. That would mean someone over 16 feet tall.\n",
    "\n",
    "What should we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-17T22:09:28.682056Z",
     "start_time": "2022-10-17T22:09:28.635966Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write your code here to investigate it further\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T20:23:30.433735Z",
     "start_time": "2020-03-02T20:23:30.427791Z"
    }
   },
   "source": [
    "### Set number of bins or bin width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T19:59:30.880313Z",
     "start_time": "2023-01-05T19:59:30.830500Z"
    }
   },
   "outputs": [],
   "source": [
    "if type(heights[0]) == int:\n",
    "    delta = 2\n",
    "    n_bins = (h_max - h_min) / delta\n",
    "    n_bins = int(n_bins) + 1\n",
    "    print(f\"Using {n_bins} bins with width {delta}.\")\n",
    "\n",
    "else:\n",
    "    n_bins = 10\n",
    "    delta = (h_max - h_min) / n_bins\n",
    "    print(f\"Using {n_bins} bins with width {delta}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T19:59:33.792428Z",
     "start_time": "2023-01-05T19:59:33.692330Z"
    }
   },
   "outputs": [],
   "source": [
    "frequencies = [0] * n_bins\n",
    "boundaries = [h_min + delta]\n",
    "for i in range(n_bins):\n",
    "    boundaries.append(boundaries[-1] + delta)\n",
    "\n",
    "print(f\"Defined {len(boundaries)} bin boundaries and placed them at\\n{boundaries}.\\n\")\n",
    "\n",
    "for h in heights[:]:\n",
    "    k = 0\n",
    "    while h > boundaries[k]:\n",
    "        k += 1\n",
    "    \n",
    "    frequencies[k] += 1\n",
    "#     print(h, k)\n",
    "\n",
    "# Test we included all data points\n",
    "assert(sum(frequencies) == len(heights))\n",
    "\n",
    "print(f\"The measured frequencies are:\\n{frequencies}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make frequency plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T19:59:38.012982Z",
     "start_time": "2023-01-05T19:59:37.673119Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize = (12, 4.5) )\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "my_font_size = 15\n",
    "half_frame(ax, \"height\", \"Frequency\", font_size = my_font_size)\n",
    "\n",
    "xticks = [h_min]\n",
    "xticks.extend(boundaries)\n",
    "x_values = np.array(boundaries[:-1]) - (delta/2. + 0.5)\n",
    "\n",
    "ax.plot(x_values, frequencies, 'o-', lw = 2)\n",
    "ax.set_xticks(xticks)\n",
    "\n",
    "# print(xticks)\n",
    "# print(x_values)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T19:59:42.849617Z",
     "start_time": "2023-01-05T19:59:42.491812Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize = (12, 4.5) )\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "my_font_size = 15\n",
    "half_frame(ax, \"height\", \"Probability density\", font_size = my_font_size)\n",
    "\n",
    "pdf = np.array(frequencies) / len(heights) / delta\n",
    "\n",
    "ax.plot(x_values, pdf, 'o-', lw = 2)\n",
    "ax.set_xticks(xticks) \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T19:59:46.172200Z",
     "start_time": "2023-01-05T19:59:45.981971Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cumulative distribution and the survival function\n",
    "#\n",
    "\n",
    "flag = 'sf'\n",
    "# flag = 'cd'\n",
    "y_label = {'sf': 'Survival function', 'cd': 'Cumulative distribution'}\n",
    "my_color = {'sf': 'r', 'cd': 'b'}\n",
    "\n",
    "cumulative = [0]\n",
    "x_values = list( range(h_min, h_max + 1) )\n",
    "for h in x_values:\n",
    "    cumulative.append( cumulative[-1] + heights.count(h))\n",
    "    \n",
    "x_values.insert(0, h_min - 1)\n",
    "# print(x_values)\n",
    "# print(cumulative)\n",
    "\n",
    "if flag == 'sf':\n",
    "    my_array = 1. - np.array(cumulative) / len(heights)\n",
    "elif flag == 'cd':\n",
    "    my_array = np.array(cumulative) / len(heights)\n",
    "\n",
    "fig = plt.figure( figsize = (6, 4.5) )\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "my_font_size = 15\n",
    "half_frame(ax, \"height\", y_label[flag], font_size = my_font_size)\n",
    "\n",
    "ax.plot(x_values, my_array, '-', color = my_color[flag], lw = 2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T19:59:50.396885Z",
     "start_time": "2023-01-05T19:59:50.345445Z"
    }
   },
   "outputs": [],
   "source": [
    "print(my_array[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
