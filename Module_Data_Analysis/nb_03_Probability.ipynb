{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synopsis\n",
    "\n",
    "\n",
    "This notebook provides a quick overview of the histories of probability theory and statistics. It then briefly introduces some concepts in probability theory, including:\n",
    "\n",
    "* Events, micro-states, macro-states\n",
    "* Sample spaces \n",
    "* Axioms of probability\n",
    "* Functions of random variables\n",
    "* Connection to statistical physics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T21:27:46.764777Z",
     "start_time": "2023-02-05T21:27:46.719157Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from colorama import Back, Fore, Style\n",
    "from copy import copy, deepcopy\n",
    "from pathlib import Path\n",
    "from sys import path\n",
    "\n",
    "path.append( str(Path.cwd().parent) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T21:27:52.775485Z",
     "start_time": "2023-02-05T21:27:52.735165Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import scipy.stats as stats\n",
    "\n",
    "from Amaral_libraries.my_stats import half_frame, get_product_sample_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T21:27:55.481833Z",
     "start_time": "2023-02-05T21:27:55.436187Z"
    }
   },
   "outputs": [],
   "source": [
    "my_fontsize = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A brief history of probability theory (see [Wikipedia article](https://en.wikipedia.org/wiki/History_of_probability))\n",
    "\n",
    "To the best of my knowledge, the systematic study of probabilities started in Europe in the 1500s. **Girolamo Cardano**, a mathematician born in Pavia, introduced the binomial expansion (see [Wikipedia article](https://en.wikipedia.org/wiki/Gerolamo_Cardano) for the source of these sentences)\n",
    "\n",
    "> $(x + y)^n$\n",
    "\n",
    "and the binomial coefficients. He was apparently \"notoriously short of money and kept himself solvent by being an accomplished gambler and chess player\". He used the game of throwing dice to understand the basic concepts of probability. He demonstrated the efficacy of defining odds as the ratio of favorable to unfavorable outcomes.\n",
    "\n",
    "His book about games of chance, *Liber de ludo aleae* (\"Book on Games of Chance\"), written around 1564, but not published until 1663, contains the first systematic treatment of probability, as well as a section on effective cheating methods. One has to wonder if others able to reach the same understanding of stochastic/random/aleatory processes chose to keep that knowledge to themselves.\n",
    "\n",
    "The French mathematicians **Pierre de Fermat** and **Blaise Pascal** took the torch from Cardano. Through their correspondence in the 1650s, they set the foundations of probability theory. Pascal developed an arithmetic approach to calculate the binomial coefficients, which ended up being called **Pascal's triangle**. Fermat is credited with carrying out the first-ever rigorous probability calculation. In it, he demonstrated why a professional gambler was correct in his experience that if he bet on rolling at least one six in four throws of a die he won in the long term, whereas betting on throwing at least one double-six in 24 throws of two dice resulted in his losing.  \n",
    "\n",
    "It is important to understand the importance of scientific correspondence at this time.  This was before there were scientific journals.  Scientists advertised their work through letters to their colleagues and rivals.  Those letter would then be transcribed and discussed at salons around Europe.  An accomplished scientist might eventually publish his $-$ they were mostly men who did this even though many women participated in the salon discussions $-$ work in book form.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the results presented in Fermat and Pascal's correspondence ended up in book form due to **Christiaan Huygens**' publication of *Van Rekeningh in Spelen van Gluck* (\"Reasoning on Games of Chance\"). Huygens introduced the concept of **expected value**.\n",
    "\n",
    "Huygens' book later inspired the work of **Jacob Bernoulli** and **Pierre-Simon Laplace**.  The Swiss mathematician Bernoulli is also responsible for defining the **Bernoulli trial**, a stochastic 'experiment' with two possible outcomes ('failure' and 'success') and a constant probability of success $p$. He wrote an influential book on probabilities $-$ *Ars Conjectandi* (\"The Art of Casting\") $-$ which was published after his death. In the book, Bernoulli makes the first known derivation of the law of large numbers, a **theorem** that describes the result of performing the same experiment a large number of times. According to the law, the average of the results obtained from a large number of trials should approach the **expected value** as the number of trials tends to infinity. \n",
    "\n",
    "The French polymath Laplace was the one the most accomplished scientist of Western Europe. He was responsible for advances on many fields.  Among his contributions to probability theory and statistics, stands his 1812 book *Théorie analytique des probabilités* (\"Analytical Theory of Probabilities\"). The first half of the book dealt with  probability methods, the second half with statistical methods and applications. \n",
    "\n",
    "In his *Essai philosophique sur les probabilités* (1814), Laplace set out a mathematical system of inductive reasoning based on probability, which we would today recognize as Bayesian. He begins the text with a set of \"principles of probability\":\n",
    "\n",
    "> 1. Probability is the ratio of the *favored events* to the total possible events.\n",
    ">\n",
    "> > $P(s) = \\frac{s}{n}$\n",
    ">\n",
    "> 2. The first principle assumes equal probabilities for all events. When this is not true, we must first determine the probabilities of each event. Then, the probability is the sum of the probabilities of all possible favored events.\n",
    ">\n",
    "> 3. For independent events, the probability of the occurrence of all is the probability of each multiplied together.\n",
    ">\n",
    "> > $P(B, A) = P(A)~P(B)$\n",
    ">    \n",
    "> 4. For events not independent, the probability of event B following event A (or event A causing B) is the probability of A multiplied by the probability that, given A, B will occur.\n",
    ">\n",
    "> > $P(B, A) = P(A)~P(B~|~A)$\n",
    ">\n",
    "> 5. The probability that A will occur, given that B has occurred, is the probability of A and B occurring divided by the probability of B.\n",
    ">\n",
    "> > $P(A~|~ B) = \\frac{P(A~ \\cap~ B)}{P(B)}$ \n",
    "\n",
    "One well-known formula arising from Laplace's system is the rule of succession, given as principle seven. Suppose that some trial has only two possible outcomes, labeled *success* and *failure*. Under the assumption that little or nothing is known a priori about the relative plausibilities of the outcomes, Laplace derived a formula for the probability that the next trial will be a success.\n",
    "\n",
    "> $P({\\text{next outcome is success}}) = \\frac {s+1}{n+2}$\n",
    "\n",
    "where $s$ is the number of previously observed successes and $n$ is the total number of observed trials. It is still used as an estimator for the probability of an event if we know the event space, but have only a small number of samples.  **The rule of succession has an advantage over simply using the first principle on finite data.  The first principle would set the probability of any unobserved outcome to zero. Thus, it cannot even be used in the absence of any data**. \n",
    "\n",
    "Later in the 19$^{th}$  century, the probabilistic approach to stochastic processes was exploited by the Physicists **Ludwig Boltzmann** and **J. Willard Gibbs** to develop statistical physics. Below, I provide an example.  \n",
    "\n",
    "The axiomatic approach to probability was fully developed by the Russian polymath **Andrey Kolmogorov** in his  *Foundations of the Theory of Probability* (1933). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A brief history of statistics (see [Wikipedia article](https://en.wikipedia.org/wiki/History_of_statistics))\n",
    "\n",
    "While initially statistics referred to the collection of data and their description (what is now called *descriptive statistics*), it grew to include the analysis and interpretation of data (what is now called *inferential statistics*).  It is in the domain of inferential statistics that probability theory comes in and connects to statistics.\n",
    "\n",
    "The word statistics is derived from the New Latin *statisticum collegium* (\"council of state\") and the Italian word *statista* (\"statesman\" or \"politician\"). The reason is that statistics owns its existence to the needs of the bureaucratic state. How many people are there? Where do they live? How long will they live? What do they produce? What do they consume? How many can we conscript for our armies? \n",
    "\n",
    "<img src = \"Images/westminster_abbey_pyx.png\" width = 400>\n",
    "\n",
    "Both the **Han Dynasty** and the **Roman Empire** extensively gathered data on the size of the empire's population, geographical area and wealth (descriptive statistics). The first recorded example of inferential statistics in Western Europe was the **Trial of the Pyx**, which is a test of the purity of the coinage of the Royal Mint. Starting in the 12$^{th}$ century, the Trial used as a statistical sampling method. After minting a large number of coins, a single coin was selected and placed in the Pyx $-$ a box in Westminster Abbey (see photo, pyx is the name for a container to store consecrated hosts). After a given period, the coins were removed and weighed and a smaller sample were tested for purity. \n",
    "\n",
    "In 1662, **John Graunt** and **William Petty** developed early census methods that provided a framework for modern demography. They produced the first life table, which tabulate the probabilities of survival to each age. In his book *Natural and Political Observations Made upon the Bills of Mortality*, Graunt used analysis of the mortality rolls to make the first statistically based estimation of the population of London.  \n",
    "\n",
    "In 1710, **John Arbuthnot** investigated the human sex ratio at birth. He consulted birth records in London for the period 1629 to 1710 (82 years), and found that the number of males born in London exceeded the number of females in every year. Assuming an equal ratio, the probability of observing more male than female births in a year would be 1/2. Thus the probability of the observed outcome under this hypothesis would be $0.5^{82}$.  This is vanishingly small, leading Arbuthnot to conclude that this was not due to chance, but to \"divine providence\". For this and similar work, Arbuthnot is credited as the first user of **significance tests**.  \n",
    "\n",
    "In the past, accomplished scientists made important contributions to statistics. **Isaac Newton** was employed by the the Royal Mint and worked to uniformize coinage. Laplace made important contributions to demographics. **Johann Carl Friedrich Gauss** spent 14 years later in life surveying the territory of Hanover. \n",
    "\n",
    "From the beginning, statistics would also play a critical role in the development of science and the scientific method $-$ testing scientific hypotheses and models. In the 1500s, **Tycho Brahe** used the **arithmetic mean** to reduce the error in his estimates of the position of celestial bodies. The English mathematicians **Roger Cotes** and **Thomas Simpson** developed the **theory of errors**, which postulates how measurements may differ from actual values.  This work would lead to the development of the normal distribution.\n",
    "\n",
    "The English economist **William Playfair** introduced the idea of graphical representation into statistics. His *Statistical Breviary* (1801) popularized the line chart, bar chart, pie chart, and histogram. In 1801, Gauss developed and applied the **method of least squares** to accurately predict the orbit of Ceres $-$ a dwarf planet in the asteroid belt $-$ using only a few data points corresponding to less than 1% of the entire orbit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The development of modern mathematical statistics owes much to the work of English polymath (and racist) **Francis Galton** and his (also racist) compatriot **Karl Pearson**.  Galton introduced many important statistical concepts, including the standard deviation, correlation, regression. He applied these methods to the study of the variety of human characteristics $-$ height, weight, and eyelash length among others $-$ and found that many of these could be well fitted to a normal curve distribution.  Galton's study of the accuracy of 787 guesses of the weight of an ox at a country fair, lead to the concept of **wisdom of the crowd**.\n",
    "\n",
    "Pearson's work, and that of Galton's, underpins many of the \"classical\" statistical methods that we will study in these materials.  They include the correlation coefficient, the method of moments for the estimation of the parameters of distributions fitted to samples, and the P-value.  Pearson emphasized the statistical foundation of scientific laws and initiated the concept of statistical hypothesis testing. Pearson also developed a powerful dimensionality reduction technique $-$ principal component analysis.\n",
    "\n",
    "**Ronald Aylmer Fisher**, a racist English polymath, is frequently credited as the genius who \"almost single-handedly created the foundations for modern statistical science\". Fisher pioneered the **principles of the design of experiments** and developed computational algorithms for analyzing data from his balanced experimental designs. Critically, he pursued the analysis of real data as the springboard for the development of new statistical methods. Fisher's book *Statistical Methods for Research Workers* (1925) became the standard reference for the teaching and study of statistics. It was followed in 1935 by *The Design of Experiments*, which was also widely used. \n",
    "\n",
    "In addition to analysis of variance, Fisher named and promoted the **method of maximum likelihood estimation** as a replacement for the method of moments and the method of least squares. Fisher is also responsible for the popularity of the 5% level of significance. He stated that deviations exceeding twice the standard deviation are regarded as significant. Before him, deviations exceeding three times the **probable error** were considered significant. For a normal distribution, the probable error is approximately 2/3 of the standard deviation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli trials and Bernoulli processes\n",
    "\n",
    "A **binomial trial** or **Bernoulli trial** is a random 'experiment' with two possible outcomes: *success* and *failure*.  The probability of success in an individual trial is denoted $p$ and **is assumed to be constant**. \n",
    "\n",
    "Examples of Bernoulli trials include:\n",
    "\n",
    "> Tossing a coin $-$ getting `heads` is success, getting `tails` is failure.\n",
    "> \n",
    "> Rolling a die $-$ rolling a `1` is success, `any other outcome` is failure.\n",
    ">\n",
    "> Drawing a card from a shuffled deck $-$ getting an `Ace` is success. `any other outcome` is failure.\n",
    ">\n",
    "> Birth of child $-$ getting a `girl ` is success, `any other outcome` is failure.\n",
    ">\n",
    "> Football match involving Portugal $-$ Portugal `winning` is success, `any other outcome` is failure.\n",
    "\n",
    "A **Bernoulli process** is a finite or infinite sequence of Bernoulli trials.  The outcome of trial $i$ is denoted $X_i$ and it can take values in $\\{0, 1\\}$, where `1` is success and `0` is failure.\n",
    "\n",
    "We will learn some of the properties of Bernoulli processes when discussing [discrete random variables](nb_09_Discrete_random_variables.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equi-probability assumption, i.e., maximum entropy\n",
    "\n",
    "The equi-probability assumption states that every simple outcome in a process has the same probability of occurring. For example, when rolling a die, the probability of getting any face value is identical $P(i) = p$. \n",
    "\n",
    "> $P(1) + P(2) + P(3) + P(4) + P(5) + P(6) = 6p$   .\n",
    "\n",
    "If we further assume that when rolling a die we will always obtain a single face $-$ i.e., the die always settles onto an stable equilibrium position $-$ then the probabilities of getting each of the faces must add up to one.\n",
    "\n",
    "> $1 = P(1 \\lor 2 \\lor 3 \\lor 4 \\lor 5 \\lor 6)$  ,\n",
    "\n",
    "where $\\lor$ is a logical `or`.  Thus,\n",
    "\n",
    "> $6p = 1 \\Rightarrow p = \\frac{1}{6}$  .\n",
    "\n",
    "If the assumption $P(i) = p$ holds, then we say that **the die is fair**.   The idea of fairness comes from the observation that everyone has the same information.  If a die is loaded, then just some people know that this is the case and what kind of bias the die has, providing them with an unfair advantage in a game of chance involving the die.\n",
    "\n",
    "This concept of fairness as everyone holding the same information is the reason why insider trading is illegal. Unless, of course, you are a member of congress or a market maker, in which case it is just par for the course.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Micro-states, macro-states, events, and sample spaces \n",
    "\n",
    "A possible outcome from a random process defines a **micro-state**. For example, a tossed coin has two possible micro-states: `Head` and `Tail`. Two tossed coins have four micro-states: `Head_Head`, `Head_Tail`, `Tail_Head`, and `Tail_Tail`.\n",
    "\n",
    "\n",
    "The set of all possible outcomes of a random process is called the **Sample space**, and it is usually denoted by $S$. **Sample spaces can be discrete (and thus countable) or continuous (uncountable)**.\n",
    "\n",
    "A subset of the sample space is called an **event**. Examples of events for two tossed coins are `2 heads`, `at least 1 head`, `equal faces`.  A set of micro-states with some particular characteristic can also be called a macro-state.\n",
    "\n",
    "Typically, one wants to know the likelihood that a given event will occur. For example, \n",
    "\n",
    "> What is the probability of `tossing 2 heads`? \n",
    ">\n",
    "> What is the probability that `your favorite team wins the Super Bowl`?\n",
    ">\n",
    "> What is the probability of [`nuclear war`](https://www.wired.com/story/micromorts-nuclear-war/)?\n",
    "\n",
    "\n",
    "**Some times defining the sample space is easy (outcomes of tossing two coins), sometimes it is very very hard (*known unknowns and unknown unknowns*)**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample spaces and counting techniques\n",
    "\n",
    "Nowadays, calculating sample spaces is made dramatically easy by the availability of powerful computers. However, for some situations even a very powerful computer will be useless because sample spaces can grow so fast in size.\n",
    "\n",
    "In order to determine the size of sample spaces or the size of certain events, one uses **counting techniques**.\n",
    "\n",
    "The size of the sample space of rolling a die and tossing a coin can be calculated by **multiplying** the size of the individual sample spaces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T21:29:07.887731Z",
     "start_time": "2023-02-05T21:29:07.840018Z"
    }
   },
   "outputs": [],
   "source": [
    "toss_coin = {'Heads', 'Tails'}\n",
    "roll_6_die = {1, 2, 3, 4, 5, 6}\n",
    "card_suits = {'Spades', 'Hearts', 'Diamonds', 'Clubs'}\n",
    "card_ranks = {2, 3, 4, 5, 6, 7, 8, 9, 10, 'Jack', 'Queen', 'King', 'Ace'}\n",
    "\n",
    "simple_sets = [toss_coin, roll_6_die]\n",
    "events = get_product_sample_space( simple_sets )\n",
    "print( f\"\\nThere are {len(set(events))} by combining the simple events \"\n",
    "       f\"from the sets {simple_sets}.\\n\" )\n",
    "print(events)\n",
    "print()\n",
    "\n",
    "events = sorted( list( itertools.product( *simple_sets ) ) )\n",
    "print( f\"\\nThere are {len(events)} by combining the simple events \"\n",
    "       f\"from the sets {simple_sets}.\\n\" )\n",
    "print(events)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T21:29:47.606225Z",
     "start_time": "2023-02-05T21:29:47.562746Z"
    }
   },
   "outputs": [],
   "source": [
    "simple_sets = [card_ranks, card_suits]\n",
    "events = get_product_sample_space( simple_sets )\n",
    "print( f\"\\nThere are {len(set(events))} by combining the simple events \"\n",
    "       f\"from the sets {simple_sets}.\\n\" )\n",
    "print(events)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "Another type of sample space arises from **permutations**. Order matters for permutations, which refer to different ordering of the $n$ items in a set.  The number of permutations of the $n$ elements in a set is \n",
    "\n",
    "> $P_n = n!$ \n",
    "\n",
    "\n",
    "If we are only interested in permutations of $r$ elements drawn from a set of $n$ elements, then we have\n",
    "\n",
    "> $P_{r,n} = \\frac{n!}{(n-r)!}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T19:31:09.578700Z",
     "start_time": "2023-01-05T19:31:09.536004Z"
    }
   },
   "outputs": [],
   "source": [
    "simple_events = {'A', 'B', 'C', 'D'}\n",
    "r = 2\n",
    "\n",
    "events = sorted( list( itertools.permutations(simple_events, r = r) ) )\n",
    "\n",
    "print( f\"There are {len(set(events))} permutations of the set \"\n",
    "       f\"{simple_events} with {r} elements.\\n\" )\n",
    "print(events)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "\n",
    "While order matters for permutations, there are situations in which we are also drawing from a single set **without replacement** but the order does not matter.  For example, consider a Powerball-like lottery game in which we are drawing 6 balls out of a possible 69. What are the number of **combinations** $-$ that is, possible outcomes?\n",
    "\n",
    "The number of distinct subsets of $r$ elements that can be drawn from a possible set of $n$ is given by:\n",
    "\n",
    "> $C_r^n = \\frac{n!}{k!(n-r)!}$\n",
    "\n",
    "You have already encountered this expression for the Pascal's triangle problem. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T19:31:11.431210Z",
     "start_time": "2023-01-05T19:31:11.374820Z"
    }
   },
   "outputs": [],
   "source": [
    "simple_events = {'A', 'B', 'C', 'D', 'E'}\n",
    "r = 2\n",
    "\n",
    "events = sorted( list( itertools.combinations( simple_events, r = r ) ) )\n",
    "\n",
    "print( f\"There are {len(set(events))} combinations of length {r} of the set \"\n",
    "       f\"{simple_events}.\\n\" )\n",
    "print(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "In some situations, one may be interested in combinations drawing from a single set but **with replacement**. The number of **combinations** in this case is:\n",
    "\n",
    "\n",
    "> $CR_r^n = C_{r}^{n+r-1}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-13T20:55:33.416046Z",
     "start_time": "2023-01-13T20:55:33.180149Z"
    }
   },
   "outputs": [],
   "source": [
    "simple_events = {'A', 'B', 'C', 'D', 'E'}\n",
    "r = 2\n",
    "\n",
    "events = sorted( list( itertools.combinations_with_replacement( simple_events, r = r ) ) )\n",
    "\n",
    "print( f\"There are {len(set(events))} combinations with replacement of \"\n",
    "       f\"length {2} of the set {simple_events}.\\n\" )\n",
    "print(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kolmogorov's axioms of probability\n",
    "\n",
    "In the an axiomatic view of probability, the **probability** of an event belonging to the sample space $S$ is a number that can be assigned to the event and that satisfies the following properties:\n",
    "\n",
    "> **Axiom 1:** $P(S) = 1$\n",
    ">\n",
    "> **Axiom 2:** $0 \\le P(E) \\le 1$ for $E \\subset S$ \n",
    ">\n",
    "> **Axiom 3:** If $E_1 \\cap E_2 = \\emptyset$, then $P(E_1 \\cup E_2) = P(E_1) + P(E_2)$\n",
    "\n",
    "Let's see what these axioms mean in a concrete case $-$ yes, a die. With a die, we have 6 possible distinct outcomes: \n",
    "\n",
    "> $S = \\{ 1, 2, 3, 4, 5, 6 \\}$ ,\n",
    "\n",
    "so the probability of getting any of those six outcomes must equal 1: $P(S) = 1$.  \n",
    "\n",
    "Let us define some events to play with:\n",
    "\n",
    "> $E_1 = \\{ 1 , 2 \\}$,  $E_2 = \\{ 1 , 3 \\}$, $E_3 = \\{ 3 \\}$\n",
    "\n",
    "All these events are sub-sets of $S$, so the second axiom applies.  Axiom 2 tells us that the probability of each of those events should be greater or equal to 0 and smaller or equal to 1.  This clearly makes sense.  In fact, we can tell that each of these events has a probability greater than 0 and smaller than 1.\n",
    "\n",
    "What about the third axiom? If we consider $P(E_1 \\cup E_2)$, we can see that $E_1 \\cap E_2 \\ne \\emptyset$.  On the other hand, for $P(E_1 \\cup E_3)$, we can see that $E_1 \\cap E_3 = \\emptyset$, so \n",
    "\n",
    "> $P(E_1 \\cup E_3) = P(E_1) + P(E_3)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these axioms, it follows that \n",
    "\n",
    "> Probability of empty set: $P(\\emptyset) = 0$\n",
    ">\n",
    "> Probability of sample space minus some event: $P(S-E) = 1 - P(E)$\n",
    ">\n",
    "> Probability of sub-set of subset: $E_1 \\subset E_2 \\Rightarrow P(E_1) \\le P(E_2)$\n",
    ">\n",
    "> Probability of two independent events: $E_1$ is independent of $E_2 \\Rightarrow P(E_1 \\land E_2) = P(E_1)~P(E_2)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connection to statistical physics and kinetic theory\n",
    "\n",
    "The concepts used so far are crucial to *statistical physics*, which provided a mechanistic understanding of *Thermodynamics*. \n",
    "\n",
    "Consider a **cubic box** containing $n$ particles. Particles are moving around and colliding with the walls and one another. \n",
    "\n",
    "The equi-probabilty assumption, let us conclude that every has an equal probability of being in any section of the box. Further, assuming we are dealing with point particles without attractive interactions, it follows that the position of a particle is independent from the position of the other particles.\n",
    "\n",
    "In order to get some intuition for the implications of these simple assumptions, let us partition the box into 8 smaller cubes and label each cube with a number between 1 and 8. **What is the sample space for this problem when $n = 2$?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:08:12.703501Z",
     "start_time": "2020-01-24T21:08:12.695376Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about for $n = 10$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many events correspond to all the particles being in box 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the frequentist interpretation of probability and in statistical physics, **the probability of a macro-state (event) is the ratio of the number of micro-states that satisfying the event condition to the total number of micro-states in the sample space**.\n",
    "\n",
    "So, what is the probability of finding all particles in box 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the probability of finding $k = 1, \\dots, n$ particles inside box 1? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions of random variables\n",
    "\n",
    "Imagine that you are an insurance company ans you trying to decide how much to charge Florida homeowners for insuring their houses. In order to estimate your costs related to covering claims, you need to have information about the costs associated with a particular type of storm and the frequency of each type of storm.\n",
    "\n",
    "Replace S since I am using it fr Sample Space\n",
    "\n",
    "Let $P(S)$ be the probability of a storm with a strength $S$ occurring within a one week period during the Summer or Fall. Assume also, that the amount of damages to homes is some function of $S$\n",
    "\n",
    "> $C(S)$  .\n",
    "\n",
    "What is the distribution of payouts?\n",
    "\n",
    "Let's assume that S is a continuous variable, then \n",
    "\n",
    "> $1 = \\int_0^{S_m} ~p(S)~dS$\n",
    "\n",
    "and\n",
    "\n",
    "> $1 = \\int_0^{C_m} ~q(C)~dC$\n",
    "\n",
    "It then follows that \n",
    "\n",
    "> $q(C)~dC = p(S)~dS $\n",
    "\n",
    "and \n",
    "\n",
    "> $q(C) = p(S)~\\frac{dS}{dC}$.\n",
    "\n",
    "For $p(S) = e^{-S}$ and $C(S) = S^2$, we find\n",
    "\n",
    "> $S = \\sqrt{C}$ ,\n",
    ">\n",
    "> $q(C) = e^{-\\sqrt{C}} ~\\frac{d \\sqrt{C}}{dC}$\n",
    ">\n",
    "> $~~~~~~~= \\frac{1}{2 ~\\sqrt{C}} ~e^{-\\sqrt{C}} ~ $.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-13T21:07:37.992853Z",
     "start_time": "2023-01-13T21:07:37.025502Z"
    }
   },
   "outputs": [],
   "source": [
    "s = np.arange(0.1, 10., 0.1)\n",
    "c = np.arange(0.1, 100., 0.1)\n",
    "\n",
    "fig = plt.figure( figsize = (12, 5) )\n",
    "ax = []\n",
    "\n",
    "ax.append( fig.add_subplot(121))\n",
    "half_frame(ax[-1], 'Strength, S', 'Probability density', font_size = my_fontsize)\n",
    "ax[-1].semilogy(s, np.exp(-s), 'b-', lw = 2)\n",
    "\n",
    "ax[-1].set_xlim(0, 10)\n",
    "ax[-1].set_ylim(0.00001, 1)\n",
    "\n",
    "ax.append( fig.add_subplot(122))\n",
    "half_frame(ax[-1], 'Cost, C', 'Probability density', font_size = my_fontsize)\n",
    "ax[-1].semilogy(c, 1/2*np.sqrt(1/c)*np.exp(-np.sqrt(c)), 'r-', lw = 2)\n",
    "\n",
    "ax[-1].set_xlim(0, 100)\n",
    "ax[-1].set_ylim(0.00001, 1)\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "\n",
    "So, why was the gambler correct? Why is it smart to bet on rolling at least one six in four throws, but not to bet on rolling a double-6 in twenty four throws of two dice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
