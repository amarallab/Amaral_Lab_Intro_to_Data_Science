{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synopsis\n",
    "\n",
    "Regression analysis is one of the most common types of analysis of data in science.  \n",
    "\n",
    "##  Words to remember\n",
    "\n",
    "**ordinary least squares (OLS) regression**\n",
    "\n",
    "**intercept**\n",
    "\n",
    "**linear coefficient**\n",
    "\n",
    "**residuals**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T20:08:44.330519Z",
     "start_time": "2023-01-05T20:08:43.838632Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from colorama import Back, Fore, Style\n",
    "from pathlib import Path\n",
    "from sys import path\n",
    "\n",
    "path.append( str(Path.cwd().parent) )\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T20:08:44.408191Z",
     "start_time": "2023-01-05T20:08:44.390379Z"
    }
   },
   "outputs": [],
   "source": [
    "my_fontsize = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T20:08:50.838376Z",
     "start_time": "2023-01-05T20:08:50.146068Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from copy import copy\n",
    "from matplotlib import gridspec\n",
    "from random import sample, choice, choices\n",
    "\n",
    "from Amaral_libraries.my_stats import half_frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "Science and engineering are about obtaining associations between multiple variables. For example, the ideal gas law relates several quantities that can be measured for a gas sample:\n",
    "\n",
    "> $ PV = n R T$.\n",
    "\n",
    "For constant volume and number of moles, the equation becomes a simple linear relationship between pressure and temperature\n",
    "\n",
    "> $ P = a T$\n",
    "\n",
    "You can imagine a situation in which some 16th Century experimental physicist was trying to determine whether there is an association between $P$ and $T$ and making noisy measurements of these two quantities.\n",
    "\n",
    "Regression analysis is a statistical approach that is used to investigate for the existence of associations such as the ones described above. The basic assumption of **linear** regression analysis is that \n",
    "\n",
    "> $y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i$ . \n",
    "\n",
    "So, \n",
    "\n",
    "> $\\epsilon_i = y_i - \\beta_0 - \\beta_1 x_i$\n",
    "\n",
    "where the $\\{\\epsilon_i\\}$ are assumed to be i.i.d. normal variables with zero mean and standard deviation $\\sigma$.\n",
    "\n",
    "If we fix the value of $X$, then we can write that\n",
    "\n",
    "> $E[Y|X = x] = \\beta_0 + \\beta_1 x + E[\\epsilon_i] = \\beta_0 + \\beta_1 x$\n",
    "\n",
    "and that\n",
    "\n",
    "> $E\\left[(Y - E[Y|X = x])^2 ~| ~X = x \\right] = E[\\epsilon_i ^2] = \\sigma^2$\n",
    "\n",
    "<br><br><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least squares estimation\n",
    "\n",
    "If we have data, $\\{x_i\\}$ and $\\{y_i\\}$, and want to estimate $\\beta_0$ and $\\beta_1$, we can accomplish it by minimizing the squared differences of the data to our linear model.\n",
    "\n",
    "> $L = \\sum^n_{i = 1} \\epsilon_i ^2 = \\sum^n_{i = 1} \\left( y_i - \\beta_0 - \\beta_1 x_i \\right)^2$\n",
    "\n",
    "The minimization process yields the solutions:\n",
    "\n",
    "> $\\hat \\beta_1 = \\frac{\\bar{xy} - \\frac{\\bar x ~\\bar y}{n}}{\\bar{ x^2 } - \\frac{\\bar x ^2}{n}}$\n",
    "\n",
    "> $\\hat \\beta_0 = \\bar y - \\beta_1 \\bar x$\n",
    "\n",
    "And $e_i = y_i - \\hat \\beta_0 - \\hat \\beta_1 x_i$ are the **residuals of the fit of the linear model to the data**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T21:55:42.437117Z",
     "start_time": "2022-12-26T21:55:42.369052Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set parameters and define noises\n",
    "n = 20\n",
    "beta_0, beta_1 = -1.0, 1.0\n",
    "sigma_y = 0.20\n",
    "\n",
    "# Set to zero if no undertainty in x measurement\n",
    "# sigma_x = sigma_y / 10\n",
    "sigma_x = 0.0\n",
    "\n",
    "# Generate noise terms for y and x variables\n",
    "x_noise = stats.norm.rvs(0, sigma_x, n+1)\n",
    "y_noise = stats.norm.rvs(0, sigma_y, n+1)\n",
    "\n",
    "# Create noisy measurements\n",
    "#\n",
    "x = np.linspace(0, 1., n+1)\n",
    "y = beta_0 + beta_1 * x + y_noise\n",
    "x = x + x_noise\n",
    "\n",
    "# Place data into dataframe\n",
    "#\n",
    "df = pd.DataFrame(list(zip(x, y)), columns=['X', 'Y'])\n",
    "\n",
    "# This is an R-style linear model construction\n",
    "model = smf.ols(formula = 'Y ~ X ', data = df)\n",
    "\n",
    "results = model.fit()\n",
    "print(f\"results is a {type(results)}\\n\")\n",
    "print(f\"results.params is a {type(results.params)}\\n\")\n",
    "print(f\"{results.params}\\n\\n\")\n",
    "\n",
    "print(\"We can access them using the .column formalism.\")\n",
    "print(f\"The intercept is {results.params.Intercept:.3f}\")\n",
    "print(f\"The coefficient for X is {results.params.X:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T21:55:47.674697Z",
     "start_time": "2022-12-26T21:55:47.615675Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"results.summary() is a {type(results.summary())}\\n\\n\")\n",
    "print(results.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "## The values on the right side of the top section deal with the quality of the fit\n",
    "\n",
    "The **$R^2$** statistic measures what proportion of the variation in the outcome Y that can be explained by the covariates/predictors. If $R^2$ is close to 1, it means that the covariates can jointly fully explain the variation in the outcome Y. This means Y can be accurately predicted (in some sense) using the covariates. Conversely, a low $R^2$ means Y is poorly predicted by the covariates. \n",
    "\n",
    "The point estimator for $R^2$ is biased. The magnitude of the bias will depend on how many observations are available to fit the model and how many covariates there are relative to this sample size. **The adjusted $R^2$** attempts to correct for the bias.\n",
    "\n",
    "The `.fit` method uses a statistical test involving the **F-statistic** to help the user decide whether a linear model fits the data significantly better than a null model that assumes just a constant term.\n",
    "\n",
    "If the **p-value** for the calculated **F-statistic** is smaller than a chosen threshold, one typically uses it to reject the null hypothesis.\n",
    "\n",
    "There is a saying that *all models are wrong but some are useful*.  There is another saying that *with 2 parameters one can fit a line but that with 5 one can fit an elephant*.\n",
    "\n",
    "Being able to reject the null hypothesis does not mean that the linear model is correct (we likely have too little data).  Having a more complex model that appears to explain the data better (larger $R^2$) does not mean that it is a better model.\n",
    "\n",
    "In order to try to balance model complexity and model ability to explain the data, one makes use of so-called information criteria (IC). The two most commonly used are the Akike IC and the Bayesian IC. When looking at a single model, the value reported for the **AIC** and the **BIC** are of no use. Only when we are comparing models and those models are related do they became useful.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "## The values on the bottom section of the summary table concern the properties of the residuals. \n",
    "\n",
    "As you recall, the assumption is that the $\\epsilon$'s are Gaussian i.i.d. random variables.  **The skewness of Gaussian random variables is 0 and the kurtosis is 3**. \n",
    "\n",
    "The **Jarqueâ€“Bera** statistic quantifies how close the sample's skewness and kurtosis are to the expected values for Gaussian distributed random variable.  The test statistic is always **nonnegative**. **If it is far from zero, it signals that the residuals are not normally distributed**. \n",
    "\n",
    "The **Durbin-Watson statistic** is used to test for **autocorrelation** of the residuals. The Durbin-Watson statistic will always have a value between 0 and 4. **A value of 2.0 indicates no autocorrelation of the residuals**. Values from 0 to less than 2 indicate positive autocorrelation and values from from 2 to 4 indicate negative autocorrelation.\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T21:56:26.675455Z",
     "start_time": "2022-12-26T21:56:26.377980Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize = (6, 4.5) )\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "half_frame(ax, \"$x$\", \"$y$\", font_size = my_fontsize)\n",
    "\n",
    "# Plot data\n",
    "#\n",
    "ax.plot(x, y, 'ro', alpha = 0.9, label = 'data')\n",
    "\n",
    "# Plot true functional dependence\n",
    "#\n",
    "ax.plot(x, beta_0 + x * beta_1,  linewidth = 3, color = 'orange',\n",
    "          label = f'Generating Model:\\n   {beta_0:.2f} + {beta_1:.2f}x')\n",
    "\n",
    "# Plot linear fit\n",
    "#\n",
    "ax.plot( x, results.params[0] + x * results.params[1], \n",
    "         '-', color = 'k', linewidth = 2, alpha = 1, \n",
    "         label = \"OLS fit:  $\\\\beta_1 = $\" + f\"{results.params[1]:.3f}\" + \n",
    "         \" $\\pm$ \" + f\"{results.bse[1]:.3f}\")\n",
    "\n",
    "# Plot estimated noise component in data\n",
    "#\n",
    "ax.vlines(x, y, results.params[0] + x * results.params[1], color = 'b')\n",
    "\n",
    "# Format legend\n",
    "ax.legend(loc = (1.1, 0.5), frameon = False, markerscale = 1.3, \n",
    "          fontsize = my_fontsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "The object returned by `model.fit()` enables us to access all values returned by `model.fit().summary()` by calling specific attributed.  For example, point estimates for the coefficients of the linear fit are accessible through the attribute `params` (see label in code cell above).\n",
    "\n",
    "A list of all attributes and methods can be found [here](https://www.statsmodels.org/0.8.0/generated/statsmodels.regression.linear_model.RegressionResults.html#statsmodels.regression.linear_model.RegressionResults).\n",
    "\n",
    "The standard errors for the coefficient estimates can be retrieved with the attribute `bse` and the confidence intervals can be retrieved with `conf_int`, which returns a pandas `dataframe`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T21:56:38.505232Z",
     "start_time": "2022-12-26T21:56:38.460874Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"results.conf_int() is a {type(results.conf_int())}\\n\")\n",
    "results.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T21:56:51.644031Z",
     "start_time": "2022-12-26T21:56:51.595700Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Confidence interval for beta_1 is [{results.conf_int()[0]['X']:.3f},\" \n",
    "      f\" {results.conf_int()[1]['X']:.3f}]\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T21:56:52.126444Z",
     "start_time": "2022-12-26T21:56:52.073593Z"
    }
   },
   "outputs": [],
   "source": [
    "results.conf_int(alpha = 0.01) # Default is alpha = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the impact of different types of association\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the case:\n",
    "\n",
    "> $y = a + b~x~~~~~$ with $b \\ll 1$ and $x \\in [0,1]$\n",
    "\n",
    "What do you expect to find? How can you test your hypothesis? Where you correct?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the case:\n",
    "\n",
    "> $y = a + b~x + c~x^2~~~~~$ with $ b \\gg c$ and $x \\in [0,1]$\n",
    "\n",
    "What do you expect to find? How can you test your hypothesis? Where you correct?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the case:\n",
    "\n",
    "> $y = a + b~x^2~~~~~$ with $x \\in [0,1]$\n",
    "\n",
    "What do you expect to find? How can you test your hypothesis? Where you correct?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the case:\n",
    "\n",
    "> $\\sigma_x \\approx \\sigma_y$\n",
    "\n",
    "What do you expect to find? How can you test your hypothesis? Where you correct?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
