{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synopsis\n",
    "\n",
    "We will explore how to extract information from PDF files that were digitally generated. That is, we are not doing any OCR because the file does contain the actual text.\n",
    "\n",
    "# Words to remember\n",
    "\n",
    "**PyPDF2**\n",
    "\n",
    "**tabula-py**\n",
    "\n",
    "**pdf2image**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:36:11.423545Z",
     "start_time": "2023-08-16T19:36:10.728718Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from colorama import Back, Fore, Style\n",
    "from copy import copy, deepcopy\n",
    "from pathlib import Path\n",
    "from sys import path\n",
    "\n",
    "path.append( str(Path.cwd().parent) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:36:16.006905Z",
     "start_time": "2023-08-16T19:36:12.648523Z"
    }
   },
   "outputs": [],
   "source": [
    "import pdf2image\n",
    "import tabula\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib.patches import Circle\n",
    "from PyPDF2 import PdfReader\n",
    "from pylab import imread, imshow\n",
    "\n",
    "from Amaral_libraries.my_stats import half_frame\n",
    "from Amaral_libraries.my_image_library import grayscale_zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:36:17.504394Z",
     "start_time": "2023-08-16T19:36:17.456566Z"
    }
   },
   "outputs": [],
   "source": [
    "my_fontsize = 15\n",
    "data_folder = Path.cwd() / 'Data' / 'Muller_2012'\n",
    "results_folder = Path.cwd() / 'Generated_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load PDF files\n",
    "\n",
    "We will work with the article:\n",
    "\n",
    "> Christopher Muller, \"Northward Migration and the Rise of Racial Disparity\n",
    "in American Incarceration, 1880–1950\", *American Journal of Sociology* **118** (2), 281–326 (September 2012).\n",
    "\n",
    "Besides the full 46 page article, we also have access to single pages with particular types of information (figures, tables, equations). \n",
    "\n",
    "We will also create PNG images from the PDF files using `pdf2image`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:36:23.327523Z",
     "start_time": "2023-08-16T19:36:20.741285Z"
    }
   },
   "outputs": [],
   "source": [
    "article = data_folder / 'Muller_2012-Northward_Migration_and_the_Rise_of_Racial.pdf'\n",
    "\n",
    "files = sorted( list( data_folder.glob('*page*.pdf') ) )\n",
    "\n",
    "page_images = []\n",
    "print(f\"The single page PDF files in Data folder are:\\n\")\n",
    "for i, file in enumerate( files ):\n",
    "    print(f\"{i:>2} ...{str(file)[103:]}\")\n",
    "    image = pdf2image.convert_from_path(file, 500)\n",
    "    file_name = str(file).replace('.pdf', '.png')\n",
    "    image[0].save(file_name, 'PNG')\n",
    "    \n",
    "    page_images.append(file_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display a single page\n",
    "\n",
    "You can change the value of *n* to {0, 1, 2, 3}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:37:13.757437Z",
     "start_time": "2023-08-16T19:37:12.428418Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 0\n",
    "print(f\"...{page_images[n][79:]}\")\n",
    "page1 = imread( page_images[n] )\n",
    "\n",
    "fig = plt.figure( figsize = (10, 24) )\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.imshow( page1 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting text\n",
    "\n",
    "We first open the article for reading and processing. For this, we will use the `PdfReader` module from `PyPDF2`.\n",
    "\n",
    "We use the option `r+b` to indicate we are opening for reading and that the file is written as bytes, not characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:37:32.136288Z",
     "start_time": "2023-08-16T19:37:32.082275Z"
    }
   },
   "outputs": [],
   "source": [
    "reader = PdfReader(open(article, 'r+b', ))\n",
    "\n",
    "print( reader.pages[0] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:37:38.493052Z",
     "start_time": "2023-08-16T19:37:38.436622Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "page = reader.pages[0]\n",
    "print(page.get_contents())\n",
    "\n",
    "print()\n",
    "print(page.extract_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Note that the header and footer information appear at the start of the string\n",
    "\n",
    "> AJS Volume 118 Number 2 (September 2012): 281–326 281/H170152012 by The University of Chicago. All rights reserved.\n",
    "0002-9602/2012/11802-0001\\$10.00\n",
    "\n",
    "And that somethings, like `H17015`, are likely character codes arising from issues with non `utf-8` encodings. \n",
    "\n",
    "<br>\n",
    "\n",
    "# Pages with images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:38:14.003946Z",
     "start_time": "2023-08-16T19:38:12.639153Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 2\n",
    "print(f\"...{page_images[n][79:]}\")\n",
    "page6 = imread( page_images[n] )\n",
    "\n",
    "fig = plt.figure( figsize = (10, 24) )\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.imshow( page6 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract text\n",
    "\n",
    "We first extract the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:38:28.399405Z",
     "start_time": "2023-08-16T19:38:28.346223Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 6\n",
    "page = reader.pages[n]\n",
    "\n",
    "print(page.get_contents())\n",
    "\n",
    "print()\n",
    "print(page.extract_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Note the header and footer at the start of the string again\n",
    "\n",
    "> Racial Disparity in Incarceration\n",
    ">\n",
    "> 287\n",
    "\n",
    "They appear to be separated by a new line...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:38:35.633057Z",
     "start_time": "2023-08-16T19:38:35.582519Z"
    }
   },
   "outputs": [],
   "source": [
    "page.extract_text()[:120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:39:42.576541Z",
     "start_time": "2023-08-16T19:39:42.529172Z"
    }
   },
   "outputs": [],
   "source": [
    "name = str(page_images[2]).split('/')[-1][:-4] + f\"_image_0.jpg\"\n",
    "\n",
    "file_name = ( results_folder / name  )\n",
    "print(f\"We will save it at:\\n\\t...{str(file_name)[103:]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `page` object that we access with `reader` has an `images` attribute. (THIS MIGHT NOT WORK)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:39:32.639304Z",
     "start_time": "2023-08-16T19:39:32.428596Z"
    }
   },
   "outputs": [],
   "source": [
    "imgs = page.images\n",
    "print(f\"There are {len(imgs)} images in page {n}.\\n\")\n",
    "\n",
    "print(f\"The information for the first figure is:  {imgs[0]}\")\n",
    "# print(type(imgs[0]))\n",
    "print()\n",
    "\n",
    "with open(file_name, \"wb\") as fp:\n",
    "    fp.write(imgs[0].data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can then read it from the file at anytime for later processing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:39:50.277952Z",
     "start_time": "2023-08-16T19:39:50.082642Z"
    }
   },
   "outputs": [],
   "source": [
    "img0 = imread(file_name) \n",
    "\n",
    "fig = plt.figure( figsize = (10, 10) )\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.imshow(img0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pages with tables\n",
    "\n",
    "Another type of information that frequently appears in documents is tabular data.\n",
    "\n",
    "`PyPDF2` does not extract tables from documents, so we will use a different package: `tabula`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:40:01.298757Z",
     "start_time": "2023-08-16T19:39:59.983906Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 3\n",
    "print(f\"...{page_images[n][79:]}\")\n",
    "page7 = imread( page_images[n] )\n",
    "\n",
    "fig = plt.figure( figsize = (10, 24) )\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.imshow(page7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract text\n",
    "\n",
    "Let's focus on page 7 of the article alone, for simplicity, and extract the text as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:40:07.930119Z",
     "start_time": "2023-08-16T19:40:07.863841Z"
    }
   },
   "outputs": [],
   "source": [
    "page = reader.pages[7]\n",
    "\n",
    "print(page.get_contents())\n",
    "\n",
    "print()\n",
    "print(page.extract_text())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "As before, the header and footer appear at the top. Unfortunately, there is no separation between the footer line and the start of the text in the page\n",
    "\n",
    "> American Journal of Sociology\n",
    ">\n",
    "> 288TABLE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:40:13.203569Z",
     "start_time": "2023-08-16T19:40:13.149096Z"
    }
   },
   "outputs": [],
   "source": [
    "page.extract_text()[:120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not great, there would be a lot to do to process this text to extract tabular data...\n",
    "\n",
    "## Using tabula-py\n",
    "\n",
    "`tabula` reads a PDF and saves tabular data items into a list of `pandas` `dataframes`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:40:28.930229Z",
     "start_time": "2023-08-16T19:40:27.641449Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 3\n",
    "list_df = tabula.read_pdf( page_images[n].replace('png', 'pdf'), pages = 1,\n",
    "                           encoding = 'utf-8')\n",
    "\n",
    "df = list_df[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall what our table looks like**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:40:54.375096Z",
     "start_time": "2023-08-16T19:40:53.987827Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize = (10, 24) )\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.imshow(page7[400:1600, 300:2800]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first see what columns we got..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:41:01.077364Z",
     "start_time": "2023-08-16T19:41:01.033590Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T22:20:28.785925Z",
     "start_time": "2023-01-11T22:20:27.603342Z"
    }
   },
   "source": [
    "OK, so many column titles are missing. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:41:03.929689Z",
     "start_time": "2023-08-16T19:41:03.882111Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:41:06.855792Z",
     "start_time": "2023-08-16T19:41:06.812451Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Native']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also clear that, in some cases, two columns of data in the table were read into a single `dataframe` column.\n",
    "\n",
    "Two factors are responsible for these failures: \n",
    "\n",
    "> The first is that the text encoding is not `utf-8`, so the minus signs get screwed.  \n",
    ">\n",
    "> The second is that some of the the columns do not have a **flat structure**.\n",
    "\n",
    "\n",
    "This means that we need to do some further processing in order to extract the data.\n",
    "\n",
    "The first column is the one with the list of time periods. Each entry is likely coded as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:41:20.844918Z",
     "start_time": "2023-08-16T19:41:20.804727Z"
    }
   },
   "outputs": [],
   "source": [
    "print(type(df.loc[2,'Unnamed: 0']))\n",
    "print(df.loc[2,'Unnamed: 0'])\n",
    "df.loc[:,'Unnamed: 0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Let's extract the times periods and add them to a **new and clean** `dataframe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:41:26.390404Z",
     "start_time": "2023-08-16T19:41:26.341794Z"
    }
   },
   "outputs": [],
   "source": [
    "my_columns = ['Time periods']\n",
    "time_periods = []\n",
    "for i in range(2, 9):\n",
    "    temp = df.loc[i,'Unnamed: 0']\n",
    "    value = temp.split()[0]\n",
    "    time_periods.append(value)\n",
    "\n",
    "print(time_periods)\n",
    "\n",
    "clean_df = pd.DataFrame(time_periods, columns = my_columns) \n",
    "clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on to other columns. Recall from above that:\n",
    "\n",
    "> some contain data from multiple columns\n",
    ">\n",
    "> `-` is extracted as `!`\n",
    ">\n",
    "> numbers are printed with commas to make it easier for human eyes to read, but that is not something that `int` knows how to operate on.\n",
    "\n",
    "We need to:\n",
    "\n",
    "> manually create the correct column names, and split the data, \n",
    "> \n",
    "> replace `!` with `-`, \n",
    ">\n",
    "> remove `,` from numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:41:46.209435Z",
     "start_time": "2023-08-16T19:41:46.166763Z"
    }
   },
   "outputs": [],
   "source": [
    "my_columns.append('Native Nonwhites - North')\n",
    "my_columns.append('Native Nonwhites - South')\n",
    "data1 = []\n",
    "data2 = []\n",
    "for i in range(2, 9):\n",
    "    temp = df.loc[i,'Native']\n",
    "    val1, val2 = temp.split()\n",
    "    data1.append( int(val1.replace('!', '-').replace(',', '')) )\n",
    "    data2.append( int(val2.replace('!', '-').replace(',', '')) )\n",
    "                 \n",
    "\n",
    "print(data1)\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "## Re-factoring\n",
    "\n",
    "We can make the code above into a function that will generate the data to be added to `clean_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:41:51.407353Z",
     "start_time": "2023-08-16T19:41:51.361491Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_data_from_tabula(df, column_name, start_index, end_index):\n",
    "    \"\"\"\n",
    "    This function takes the correct column names, split the data \n",
    "    into two columns, replaces `!` with `-`, and removes `,` from numbers.\n",
    "    \n",
    "    inputs:\n",
    "        df - dataframe returned by tabula\n",
    "        column_name - str with column name to be processed\n",
    "        start_index - int from df \n",
    "        end_index - int from df\n",
    "        \n",
    "    returns:\n",
    "        data1 - list of int\n",
    "        data2 - list of int\n",
    "        \n",
    "    \"\"\"\n",
    "    data1 = []\n",
    "    data2 = []\n",
    "    for i in range(start_index, end_index):\n",
    "        temp = df.loc[i,column_name]\n",
    "        val1, val2 = temp.split()\n",
    "        data1.append( int(val1.replace('!', '-').replace(',', '')) )\n",
    "        data2.append( int(val2.replace('!', '-').replace(',', '')) )\n",
    "        \n",
    "    return data1, data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:41:54.994072Z",
     "start_time": "2023-08-16T19:41:54.943604Z"
    }
   },
   "outputs": [],
   "source": [
    "data1, data2 = clean_data_from_tabula(df, 'Native', 2, len(df))\n",
    "\n",
    "clean_df['Native Nonwhites - North'] = data1\n",
    "clean_df['Native Nonwhites - South'] = data2\n",
    "\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:41:59.125564Z",
     "start_time": "2023-08-16T19:41:59.088083Z"
    }
   },
   "outputs": [],
   "source": [
    "data1, data2 = clean_data_from_tabula(df, 'Unnamed: 2', 2, len(df))\n",
    "\n",
    "clean_df['Native Whites - North'] = data1\n",
    "clean_df['Native Whites - South'] = data2\n",
    "\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:42:02.689530Z",
     "start_time": "2023-08-16T19:42:02.640614Z"
    }
   },
   "outputs": [],
   "source": [
    "data1, data2 = clean_data_from_tabula(df, 'Foreign', 2, len(df))\n",
    "\n",
    "clean_df['Foreign Whites - North'] = data1\n",
    "clean_df['Foreign Whites - South'] = data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking our work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:42:12.427305Z",
     "start_time": "2023-08-16T19:42:12.082087Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize = (10, 24) )\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.imshow(page7[400:1600, 300:2800]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:42:15.349716Z",
     "start_time": "2023-08-16T19:42:15.300852Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Everything looks good!**\n",
    "\n",
    "<br>\n",
    "\n",
    "# Pages with equations\n",
    "\n",
    "Another type of information that frequently appears in documents are equations and mathematical symbols.\n",
    "\n",
    "`PyPDF2` does not extract either from documents, so we would need to use use a different package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:42:27.129726Z",
     "start_time": "2023-08-16T19:42:25.742211Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 1\n",
    "print(f\"...{page_images[n][103:]}\")\n",
    "page10 = imread( page_images[n] )\n",
    "\n",
    "fig = plt.figure( figsize = (10, 24) )\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.imshow( page10 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract text\n",
    "\n",
    "Let's focus on page 10 of the article alone, for simplicity, and extract the text as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:42:31.290800Z",
     "start_time": "2023-08-16T19:42:31.234267Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "page = reader.pages[9]\n",
    "print(page.get_contents())\n",
    "\n",
    "print()\n",
    "text_in_page = page.extract_text()\n",
    "print(text_in_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Clearly somethings are getting messed up..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T19:42:36.085190Z",
     "start_time": "2023-08-16T19:42:36.044382Z"
    }
   },
   "outputs": [],
   "source": [
    "print(text_in_page[33:350].split())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The presence of italic font, symbols, and equations really messes up the text extraction.  This may have to do with  with encoding available for `PyPDF2`. The default is likely `utf8`, which is not able to encode many of the symbols appearing in equations.\n",
    "\n",
    "A possible solution to handle this type of information is to select portions of the image and use other software for processing.  [Matchpix](https://mathpix.com/ocr) is a web software that extracts `LaTeX` formatted equations from images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:new_base] *",
   "language": "python",
   "name": "conda-env-new_base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "204.567px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
