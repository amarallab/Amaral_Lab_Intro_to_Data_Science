{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synopsis\n",
    "\n",
    "Extracting information from scanned files.\n",
    "\n",
    "# Words to remember\n",
    "\n",
    "**warping**\n",
    "\n",
    "**OCR**\n",
    "\n",
    "**denoising**\n",
    "\n",
    "**blurring**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:13:55.938055Z",
     "start_time": "2023-02-12T22:13:55.154636Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from colorama import Back, Fore, Style\n",
    "from copy import copy, deepcopy\n",
    "from pathlib import Path\n",
    "from sys import path\n",
    "\n",
    "path.append( str(Path.cwd().parent) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing  Tesseract for OCR\n",
    "\n",
    "To use Tesseract, you have to install it into your computer, and also to install the `Python` package that provides an interface for it.\n",
    "\n",
    "You can find details of how to do it [here](https://builtin.com/data-science/python-ocr)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T19:29:35.616527Z",
     "start_time": "2023-01-06T19:29:35.579314Z"
    }
   },
   "outputs": [],
   "source": [
    "#conda install pyTesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:14:29.172381Z",
     "start_time": "2023-02-12T22:14:29.108756Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.patches import Circle\n",
    "from pylab import imread, imshow, imsave\n",
    "from scipy.stats import pearsonr\n",
    "from skimage import img_as_float, img_as_ubyte\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import rank, threshold_otsu, gaussian\n",
    "from skimage.measure import find_contours\n",
    "from skimage.morphology import ( disk, binary_dilation, binary_erosion, \n",
    "                                 binary_closing, binary_opening, \n",
    "                                 remove_small_holes, remove_small_objects,\n",
    "                                 flood_fill, )\n",
    "\n",
    "from skimage.transform import estimate_transform, warp\n",
    "\n",
    "# from skimage import ( transform, color, \n",
    "#                       restoration )\n",
    "\n",
    "\n",
    "from Amaral_libraries.my_stats import half_frame\n",
    "from Amaral_libraries.my_image_library import grayscale_zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:14:31.726761Z",
     "start_time": "2023-02-12T22:14:31.679359Z"
    }
   },
   "outputs": [],
   "source": [
    "my_fontsize = 15\n",
    "data_folder = Path.cwd() / 'Data' / 'Scanned_Images'\n",
    "results_folder = Path.cwd() / 'Generated_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images\n",
    "\n",
    "We load all images but select a single one for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:14:39.044154Z",
     "start_time": "2023-02-12T22:14:37.447313Z"
    }
   },
   "outputs": [],
   "source": [
    "my_images = list( data_folder.glob('*') )\n",
    "print(f\"There are {len(my_images)} images in the folder.\")\n",
    "print()\n",
    "\n",
    "plate = imread(my_images[1])\n",
    "print(f\"Selected image has shape {plate.shape}.\\n\")\n",
    "\n",
    "imshow(plate);\n",
    "\n",
    "print(f\"That fourth channel is just ones:\\n{plate[:10, :10, 3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not need the fourth channel, so we will get rid of it.\n",
    "\n",
    "We will also want to work with a grayscale version of the image.  The question is: \n",
    "\n",
    "> **Which grayscale version should we use?**\n",
    "\n",
    "Let's look at each channel separately besides a conversion to grayscale of the color image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:14:47.460209Z",
     "start_time": "2023-02-12T22:14:45.308934Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize = (10, 8) )\n",
    "ax = []\n",
    "rgb = ['red', 'green', 'blue']\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    ax.append( fig.add_subplot(2, 2, i+1) )\n",
    "    ax[-1].text(2000, -100, rgb[i], fontsize = my_fontsize )\n",
    "    ax[-1].imshow( plate[:,:,i], cmap = 'gray' )\n",
    "\n",
    "    \n",
    "ax.append( fig.add_subplot(2, 2, 4) )\n",
    "ax[-1].text(2000, -100, 'gray', fontsize = my_fontsize )\n",
    "ax[-1].imshow( rgb2gray(plate[:,:,:3]) , cmap = 'gray' )\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the **blue channel** seems to be the one where the text information and the boxes with data we want to extract is more clearly visible.\n",
    "\n",
    "From now on, we will focus on this channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:14:57.035840Z",
     "start_time": "2023-02-12T22:14:56.979893Z"
    }
   },
   "outputs": [],
   "source": [
    "plate[:,:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-18T19:12:16.487404Z",
     "start_time": "2023-01-18T19:12:16.428394Z"
    }
   },
   "source": [
    "As before, we will transform to ubytes in order to save resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:15:01.186182Z",
     "start_time": "2023-02-12T22:15:00.446040Z"
    }
   },
   "outputs": [],
   "source": [
    "print( f\"Maximum of blue channel is {plate[:,:,2].max():.3f}, \"\n",
    "       f\" minimum is {plate[:,:,2].min():.3f}\\n\")\n",
    "\n",
    "plate_b = (256 * plate[:,:,2]).astype( np.uint8 )\n",
    "\n",
    "fig = plt.figure( figsize = (12, 10) )\n",
    "plt.imshow( plate_b, cmap = 'gray', vmin = 0, vmax = 255 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct image perspective\n",
    "\n",
    "This involves two steps.  First, we will get the coordinates of the 4 corners of the blue screen as accurately as possible.  To this end, we will magnify the region around each corner one at a time, and adjust the center of the zoomed in region until the red dot is located precisely at the corner.\n",
    "\n",
    "Next, we use the `transform` package to correct the perspective of the image.  To this end, we need to provide new coordinates for the corners of the blue screen.\n",
    "\n",
    "## Specify coordinates of corners of blue screen\n",
    "\n",
    "We will use a gray scale version of the image since the zoom in function only operates with gray scale images.  \n",
    "\n",
    "**We will do one corner at a time and change the value of `k` when determining the coordinates of the corner.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:15:12.264271Z",
     "start_time": "2023-02-12T22:15:12.196356Z"
    }
   },
   "outputs": [],
   "source": [
    "# For image[1] corners are at: \n",
    "#    [[614, 445], [3620, 548], [3546, 2788], [547, 2715]]\n",
    "\n",
    "points_interest = [[614, 445], [3620, 548], [3546, 2788], [547, 2715]]\n",
    "#points_interest = [[], [], [], []]\n",
    "\n",
    "print(points_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-18T17:48:52.954024Z",
     "start_time": "2023-01-18T17:48:52.820178Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure( figsize = (10, 6))\n",
    "# ax = fig.add_subplot(111)\n",
    "\n",
    "# zoom_factor = 8\n",
    "# k = 2\n",
    "# x = 3546\n",
    "# y = 2788\n",
    "# zoomed_image, x0, y0 = grayscale_zoom(plate_b, x, y, zoom_factor)\n",
    "\n",
    "\n",
    "# ax.imshow( zoomed_image, cmap = 'gray', vmin = 0, vmax = 255 )\n",
    "# ax.plot([zoom_factor*(x-x0)], [lzoom_factor*(y-y0)], 'ro');\n",
    "\n",
    "# # Update coordinates of corner k\n",
    "# #\n",
    "# points_interest[k] = [x, y]\n",
    "# print(points_interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct perspective\n",
    "\n",
    "We specify the desired coordinates for the corners of the blue screen in such a way that its size and location are approximately preserved.\n",
    "\n",
    "In order to accomplish this, we **maintain the coordinates of the first corner** and pick the **coordinates of the opposite corner using the largest values of the coordinates from the other corners**.\n",
    "\n",
    "We then use the original and desired corner coordinates to define a matrix transformation using `transform.estimate_transform`.\n",
    "\n",
    "Finally, use apply `transform.warp` to correct the perspective of the image. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:15:23.455773Z",
     "start_time": "2023-02-12T22:15:21.915094Z"
    }
   },
   "outputs": [],
   "source": [
    "print(points_interest)\n",
    "transformed_points = [[614,445], [3620, 445], [3620, 2788], [614, 2788]]\n",
    "print(transformed_points)\n",
    "\n",
    "tform = estimate_transform( 'projective', np.array(points_interest), \n",
    "                            np.array(transformed_points) )\n",
    "\n",
    "\n",
    "plate_warp = (255 * warp(plate_b, tform.inverse)).astype( np.uint8 )\n",
    "color_plate_warp = warp(plate[:,:,:3], tform.inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:15:26.400728Z",
     "start_time": "2023-02-12T22:15:24.682051Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (12, 12))\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.imshow(plate)\n",
    "\n",
    "for point in points_interest:\n",
    "    ax1.add_patch(Circle(point, 10, facecolor = 'r'))\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.imshow( plate_warp, cmap = 'gray', vmin = 0, vmax = 255 )\n",
    "for point in transformed_points:\n",
    "    ax2.add_patch(Circle(point, 10, facecolor = 'r'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:15:31.305999Z",
     "start_time": "2023-02-12T22:15:30.441267Z"
    }
   },
   "outputs": [],
   "source": [
    "plate_corrected = plate_warp[445:2788, 614:3620]\n",
    "color_plate_corrected = color_plate_warp[445:2788, 614:3620]\n",
    "\n",
    "fig = plt.figure( figsize = (12, 10) )\n",
    "# plt.imshow( plate_corrected, cmap = 'gray', vmin = 0, vmax = 255 );\n",
    "plt.imshow( color_plate_corrected );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:15:35.984046Z",
     "start_time": "2023-02-12T22:15:35.930857Z"
    }
   },
   "outputs": [],
   "source": [
    "del plate\n",
    "del color_plate_warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:15:38.806541Z",
     "start_time": "2023-02-12T22:15:38.715792Z"
    }
   },
   "outputs": [],
   "source": [
    "print( color_plate_corrected.dtype, plate_corrected.dtype )\n",
    "\n",
    "color_plate_corrected = (255 * color_plate_corrected).astype( np.uint8 )\n",
    "\n",
    "print( color_plate_corrected.dtype, plate_corrected.dtype )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract boxes with data\n",
    "\n",
    "The data to be extracted is plotted in three graph boxes. \n",
    "\n",
    "Annoyingly, the graphs have a grid, making our job harder.  We will use Gaussian filters again to destroy the grid so that the graph boxes are uniform coupled with removal of small holes and objects.\n",
    "\n",
    "We will then use contours to identify the 3 graph boxes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove grid lines from graph boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:15:51.820695Z",
     "start_time": "2023-02-12T22:15:50.601681Z"
    }
   },
   "outputs": [],
   "source": [
    "zoom_factor = 2\n",
    "x = 450\n",
    "y = 650\n",
    "\n",
    "fig = plt.figure(figsize = (12, 8))\n",
    "ax1 = fig.add_subplot(121)\n",
    "\n",
    "zoomed_image, x0, y0 = grayscale_zoom( plate_corrected, x, y, zoom_factor )\n",
    "ax1.imshow( zoomed_image, cmap = 'gray')\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "sigma = 10\n",
    "img2 = gaussian( plate_corrected, sigma = (sigma, sigma), \n",
    "                 truncate = 3.5, preserve_range = True )\n",
    "\n",
    "plate_for_boxes = img2 > threshold_otsu(img2)\n",
    "print(f\"The array plate_for_boxes is of type {plate_for_boxes.dtype}.\\n\")\n",
    "\n",
    "zoomed_image, x0, y0 = grayscale_zoom( plate_for_boxes, x, y, zoom_factor )\n",
    "ax2.imshow( zoomed_image, cmap = 'gray' );\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "del zoomed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "And now we can take out some of the smallish holes and objects..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:15:57.989973Z",
     "start_time": "2023-02-12T22:15:57.494468Z"
    }
   },
   "outputs": [],
   "source": [
    "plate_for_boxes = remove_small_objects( plate_for_boxes, 2000 )\n",
    "plate_for_boxes = remove_small_holes( plate_for_boxes, 2000 )\n",
    "\n",
    "\n",
    "fig = plt.figure( figsize = (12, 10) )\n",
    "plt.imshow(plate_for_boxes, cmap = 'gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty cool, don't you think?\n",
    "\n",
    "## Contours\n",
    "\n",
    "We can now identify contours and eliminate all that are small.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:16:04.998466Z",
     "start_time": "2023-02-12T22:16:04.884795Z"
    }
   },
   "outputs": [],
   "source": [
    "contours = find_contours(plate_for_boxes)\n",
    "print(f\"The algorithm found {len(contours)} contours.\\n\")\n",
    "\n",
    "for j in range(len(contours)-1, -1, -1):\n",
    "    if len(contours[j]) < 5000:\n",
    "        contours.pop(j)\n",
    "\n",
    "print(f\"There are {len(contours)} good contours.\\n\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:16:09.170870Z",
     "start_time": "2023-02-12T22:16:08.787283Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize = (12, 10) )\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.imshow(plate_for_boxes, cmap = 'gray')\n",
    "\n",
    "# Find coordinates of corners of boxes\n",
    "#\n",
    "box_max = []\n",
    "box_min = []\n",
    "for n, contour in enumerate(contours):\n",
    "    ax.plot(contour[:, 1], contour[:, 0], linewidth = 2)\n",
    "    box_max.append( np.max(contour, axis = 0) )\n",
    "    box_min.append( np.min(contour, axis = 0) )\n",
    "    \n",
    "del contours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now store the sections of the image with the graph boxes and with the corresponding text into list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:16:15.574038Z",
     "start_time": "2023-02-12T22:16:15.516333Z"
    }
   },
   "outputs": [],
   "source": [
    "graph_boxes = []\n",
    "text_boxes = []\n",
    "for i in range(3):\n",
    "    temp = color_plate_corrected[int(box_min[i][0]):int(box_max[i][0]), \n",
    "                                 int(box_min[i][1]):int(box_max[i][1]), :]\n",
    "    graph_boxes.append( temp )\n",
    "    \n",
    "    temp = plate_corrected[int(box_min[i][0]):int(box_max[i][0])+50, \n",
    "                           :int(box_min[i][1])]\n",
    "    text_boxes.append( temp )\n",
    "    \n",
    "text_boxes.append( plate_corrected[int(box_max[2][0])+50:, :] )\n",
    "\n",
    "print(f\"The array in graph_boxes is of type {graph_boxes[0].dtype}.\\n\")\n",
    "print(f\"The array in text_boxes is of type {text_boxes[0].dtype}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:16:16.506527Z",
     "start_time": "2023-02-12T22:16:16.458410Z"
    }
   },
   "outputs": [],
   "source": [
    "del plate_for_boxes\n",
    "del plate_corrected\n",
    "del color_plate_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:16:18.300970Z",
     "start_time": "2023-02-12T22:16:17.381073Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize = (10, 10) )\n",
    "gs = fig.add_gridspec(4, 5)\n",
    "ax = []\n",
    "\n",
    "for i in range(3):\n",
    "    ax.append( fig.add_subplot( gs[i, 0] ) )\n",
    "    ax[-1].imshow( text_boxes[i], cmap = 'gray', vmin = 0, vmax = 255 )\n",
    "    \n",
    "    ax.append( fig.add_subplot( gs[i, 1:] ) )\n",
    "    ax[-1].imshow( graph_boxes[i] )\n",
    "    \n",
    "\n",
    "ax.append( fig.add_subplot( gs[3, :] ) )\n",
    "ax[-1].imshow( text_boxes[3], cmap = 'gray', vmin = 0, vmax = 255 )\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save graph boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:16:35.784194Z",
     "start_time": "2023-02-12T22:16:34.637419Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    imsave(results_folder / f\"graph_boxes_{i}.png\", graph_boxes[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since the morphology functions we introduced earlier assume a bright foreground and a dark background, we will invert our text boxes images too**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:16:40.137659Z",
     "start_time": "2023-02-12T22:16:40.083545Z"
    }
   },
   "outputs": [],
   "source": [
    "print(text_boxes[0][:10,:10])\n",
    "\n",
    "new_boxes = []\n",
    "for box in text_boxes:\n",
    "    new_boxes.append( (255 - box).astype( np.uint8 ) )\n",
    "\n",
    "new_boxes[0]\n",
    "\n",
    "text_boxes = new_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:16:43.482712Z",
     "start_time": "2023-02-12T22:16:43.043143Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize = (12, 7) )\n",
    "gs = fig.add_gridspec(2, 3)\n",
    "ax = []\n",
    "\n",
    "for i in range(3):\n",
    "    ax.append( fig.add_subplot( gs[0, i] ) )\n",
    "    ax[-1].imshow( text_boxes[i], cmap = 'gray' )\n",
    "    \n",
    "\n",
    "ax.append( fig.add_subplot( gs[1, :] ) )\n",
    "ax[-1].imshow( text_boxes[3], cmap = 'gray' )\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T19:34:54.047473Z",
     "start_time": "2023-01-19T19:34:53.985396Z"
    },
    "code_folding": []
   },
   "source": [
    "Clearly, the first box is the less noisy. We will focus on it first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean sections of image with text \n",
    "\n",
    "We will use optical character recognition (OCR) to extract the text in the images.  `Tesseract` is a package that can be used for this purpose.  However, for it to work appropriately, the input image must have noise minimized.\n",
    "\n",
    "## Useful plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:17:04.171092Z",
     "start_time": "2023-02-12T22:17:04.119337Z"
    }
   },
   "outputs": [],
   "source": [
    "zoom_factor = 2\n",
    "x_c = 300\n",
    "y_c = 300\n",
    "\n",
    "y_lim = 600\n",
    "x_lim = 500\n",
    "\n",
    "def plot_sections(my_image, zoom_factor, x_c, y_c, x_lim, y_lim):\n",
    "    \n",
    "    fig = plt.figure( figsize = (10, 8) )\n",
    "    gs = fig.add_gridspec(1, 3)\n",
    "    ax = []\n",
    "\n",
    "    ax.append( fig.add_subplot( gs[0, 0]) )\n",
    "    ax[-1].imshow( my_image[:y_lim,:x_lim], cmap = 'gray');\n",
    "\n",
    "    ax.append( fig.add_subplot(gs[0, 1:]) )\n",
    "    zoomed_image, x0, y0 = grayscale_zoom( my_image, x_c, y_c, zoom_factor )\n",
    "    ax[-1].imshow( zoomed_image, cmap = 'gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising\n",
    "\n",
    "We start by binarizing the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:17:10.713979Z",
     "start_time": "2023-02-12T22:17:10.487161Z"
    }
   },
   "outputs": [],
   "source": [
    "h, w = text_boxes[0].shape\n",
    "\n",
    "print(threshold_otsu( text_boxes[0] ))\n",
    "binary_mask = text_boxes[0] > threshold_otsu( text_boxes[0] )\n",
    "\n",
    "plot_sections(binary_mask, zoom_factor, x_c, y_c, x_lim, y_lim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly there are this white columns breaking the background at regular places. Maybe we can identify them and get rid of them systematically.\n",
    "\n",
    "Let's look at the average intensity by column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:17:21.090363Z",
     "start_time": "2023-02-12T22:17:20.966600Z"
    }
   },
   "outputs": [],
   "source": [
    "column_average = binary_mask.mean( axis = 0 )\n",
    "\n",
    "plt.plot(100*column_average);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful!!! We can see that wherever the average in greater than 80%, this is a spurious white column.\n",
    "\n",
    "We can set all of them to zero! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:17:28.201249Z",
     "start_time": "2023-02-12T22:17:27.989221Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(w):\n",
    "    if column_average[i] > 0.4:\n",
    "        binary_mask[:,i] = 0\n",
    "        \n",
    "plot_sections(binary_mask, zoom_factor, x_c, y_c, x_lim, y_lim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use `remove_small_objects` to get rid of some left over noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:17:38.685334Z",
     "start_time": "2023-02-12T22:17:38.463682Z"
    }
   },
   "outputs": [],
   "source": [
    "binary_clean_objects = remove_small_objects( binary_mask, 50 )\n",
    "\n",
    "plot_sections(binary_clean_objects, zoom_factor, x_c, y_c, x_lim, y_lim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good!\n",
    "\n",
    "We can now use `binary_dilation` to connect the segments in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:17:44.969508Z",
     "start_time": "2023-02-12T22:17:44.742240Z"
    }
   },
   "outputs": [],
   "source": [
    "vicinity = disk(4)\n",
    "clean_binary = binary_closing( binary_clean_objects, vicinity )\n",
    "\n",
    "plot_sections( clean_binary, zoom_factor, x_c, y_c, x_lim, y_lim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T22:19:33.864029Z",
     "start_time": "2023-01-19T22:19:33.788736Z"
    }
   },
   "source": [
    "# Re-factoring code for cleaning text_boxes\n",
    "\n",
    "We saw that the first step is binarizing, followed by removal of lines, removal of small objects, and then binary_closing. The final step is conversion to white background and black foreground."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:18:03.289787Z",
     "start_time": "2023-02-12T22:18:03.233261Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_for_ocr( my_image, column_threshold, object_threshold, radius):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    h, w = my_image.shape\n",
    "\n",
    "    fig = plt.figure( figsize = (10, 8))\n",
    "    ax = []\n",
    "    # Binarize\n",
    "    #\n",
    "    print( f\"The threshold recommended from Otsu algorithm is \"\n",
    "           f\"{threshold_otsu( text_boxes[0] )}.\\n\" )\n",
    "    binary_mask = my_image > threshold_otsu( my_image )\n",
    "    \n",
    "    # Remove lines\n",
    "    #\n",
    "    ax.append(fig.add_subplot(311))\n",
    "    column_average = binary_mask.mean( axis = 0 )\n",
    "    ax[-1].plot( column_average )\n",
    "    ax[-1].hlines( [0.2, 0.4, 0.6, 0.8], 0, w, color = '0.2' )\n",
    "    for i in range(w):\n",
    "        if column_average[i] > column_threshold:\n",
    "            binary_mask[:,i] = 0\n",
    "            \n",
    "    # Remove small objects\n",
    "    #\n",
    "    ax.append(fig.add_subplot(312))\n",
    "    binary_clean_objects = remove_small_objects( binary_mask, \n",
    "                                                 object_threshold )  \n",
    "    \n",
    "    ax[-1].imshow( binary_clean_objects, cmap = 'gray')\n",
    "    \n",
    "    # Use binary closing to connect font elements\n",
    "    #\n",
    "    ax.append(fig.add_subplot(313))\n",
    "    vicinity = disk(radius)\n",
    "    clean_binary = binary_closing( binary_clean_objects, vicinity )\n",
    "    \n",
    "    ax[-1].imshow( clean_binary, cmap = 'gray')\n",
    "    \n",
    "    plate_for_ocr = (255 - clean_binary).astype( np.uint8 )\n",
    "\n",
    "    return plate_for_ocr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:18:04.315574Z",
     "start_time": "2023-02-12T22:18:04.077835Z"
    }
   },
   "outputs": [],
   "source": [
    "plate_for_ocr = clean_for_ocr( text_boxes[2], 0.6, 40, 4 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:18:16.569911Z",
     "start_time": "2023-02-12T22:18:16.421853Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize = (10, 8) )\n",
    "plt.imshow(plate_for_ocr, cmap = 'gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR\n",
    "\n",
    "Using `Tesseract` we can see that the string extraction is actually pretty terrible because the font does not seem to be recognized well even though the image is quite noiseless.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:18:30.521448Z",
     "start_time": "2023-02-12T22:18:29.750169Z"
    }
   },
   "outputs": [],
   "source": [
    "plate_for_ocr = (255 - clean_binary).astype( np.uint8 )\n",
    "\n",
    "results = pytesseract.image_to_data( plate_for_ocr, \n",
    "                                     output_type = pytesseract.Output.DICT )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T22:19:11.617563Z",
     "start_time": "2023-02-12T22:19:11.459339Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize = (15, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.imshow(plate_for_ocr, cmap = 'gray')\n",
    "for i in range(len(results['text'])):\n",
    "    x = results['left'][i]\n",
    "    y = results['top'][i]\n",
    "\n",
    "    w = results['width'][i]\n",
    "    h = results['height'][i]\n",
    "\n",
    "    text = results['text'][i]\n",
    "    conf = int(results['conf'][i])\n",
    "    \n",
    "    if conf > 0: \n",
    "        ax.hlines([y, y+h], x, x+w, color = 'g')\n",
    "        ax.vlines([x, x+w], y, y+h, color = 'g')\n",
    "        ax.text(x, y-10, f\"text\" )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "204.567px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
