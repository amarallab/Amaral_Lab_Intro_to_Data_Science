{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synopsis\n",
    "\n",
    "In this unit we will cover:\n",
    "\n",
    "* The structure of Web pages\n",
    "* What is HTML/CSS\n",
    "* How to extract information from HTML pages\n",
    "* Techniques for navigating and scraping web pages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-17T20:38:25.791451Z",
     "start_time": "2022-10-17T20:38:25.291525Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from colorama import Back, Fore, Style\n",
    "from pathlib import Path\n",
    "from sys import path\n",
    "\n",
    "path.append('../My_libraries')\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-17T20:38:28.868140Z",
     "start_time": "2022-10-17T20:38:28.532790Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import sys\n",
    "import random\n",
    "import requests\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import HTML, display, Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detour: A (very brief) intro to HTML\n",
    "\n",
    "In the previous units, we learned how to retrieve data from Web sources using APIs. But what if the organization hosting the data does not have the forethought or resources to create an API (or if they do not want to share their data)?  Then, we have to **crawl** their website and **scrape** their data.\n",
    "\n",
    "To do this, we will be using our dependable `requests` library.  However, we will need to call upon a few other resources.  In particular, we will need to understand the code in which webpages are written.\n",
    "\n",
    "HTML is a markup language for describing web documents. It stands for **H**yper **T**ext **M**arkup **L**anguage. \n",
    "\n",
    "HTML, together with CSS (**C**ascading **S**tyle **S**heets for _styling_ web documents) and Javascript (for _animating_ web documents), is the language that is used to run web pages.\n",
    "\n",
    "HTML documents are built using a series of HTML _tags_. Each tag describes a different type of content. \n",
    "\n",
    "This is the general HTML tag structure:\n",
    "\n",
    "> ```html\n",
    "> <tagname tag_attribute1=\"attribute1value1 attribute1value2\" \n",
    ">          tag_attribute2=\"attribute2value1\">tag contents</tagname>\n",
    ">```\n",
    "\n",
    "\n",
    "* Tags (usually) have both a start (or opening) tag, <tagname> and an end (or closing) tag, </tagname>\n",
    "* Tags can also have attributes which are declared _inside_ the opening tag.\n",
    "* The actual tag _content_ goes in between the opening and closing tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tags can be contained (nested) inside other tags, which defines relationships between them:\n",
    "\n",
    "> ```html\n",
    "> <parent>\n",
    ">    <sibling1></sibling1>\n",
    ">    <sibling2>\n",
    ">        <grandchild1></grandchild1>\n",
    ">    </sibling2>\n",
    "> </parent>\n",
    "> ```\n",
    "\n",
    "* `<parent>` is the _parent_ tag of `<sibling>`\n",
    "* `<sibling1>` and `<sibling2>` are the _children_ or _direct descendant_ tags of `<parent>`\n",
    "* `<sibling1>`, `<sibling2>`, and `<grandchild1>` are the _descendant_ tags of `<parent>`\n",
    "* `<sibling1>` and `<sibling2>` are _sibling_ tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A very simple web document\n",
    "\n",
    "\n",
    "> ```html\n",
    "> <!-- This line will not be displayed because it is a comment-->\n",
    "> <!DOCTYPE html>\n",
    "> <html>\n",
    ">    <head>\n",
    ">       <title>Page Title</title> \n",
    ">    </head>\n",
    ">\n",
    ">    <body>\n",
    ">       <h1>My First Heading</h1>\n",
    ">       <p>My first paragraph.</p>\n",
    ">    </body>\n",
    "> </html> \n",
    "> ```\n",
    "\n",
    "Using the nomenclature introduced above, we see that `<h1>` and `<p>` are sibling tags, `<body>` is their parent tag, and all three are descendent tags of `<html>`\n",
    "\n",
    "When you access any URL, your browser (Chrome, Firefox, Safari, IE, etc.) is actually reading a document such as this one and using the tags within the document to decide how to render the page for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T15:57:26.747018Z",
     "start_time": "2022-09-14T15:57:26.709544Z"
    }
   },
   "outputs": [],
   "source": [
    "first_html = \"\"\"\n",
    "    <!-- This line will not be displayed because it is a comment-->\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "          <head>\n",
    "                <title>Page Title</title>\n",
    "          </head>\n",
    "  \n",
    "          <body>\n",
    "                <h1>My First Heading</h1>\n",
    "                <p>My first paragraph.</p>\n",
    "                <p>--&nbspHello World!</p>\n",
    "          </body>\n",
    "\n",
    "    </html> \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Jupyter` is able to render a (python) string of HTML code as real HTML in the notebook itself!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T15:57:38.041752Z",
     "start_time": "2022-09-14T15:57:38.003997Z"
    }
   },
   "outputs": [],
   "source": [
    "HTML(first_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The  anatomy of this simple HTML document\n",
    "\n",
    "This is how you write a comment in HTML. Comments will not show up in the browser\n",
    "\n",
    "> This line will not be displayed because it is a comment\n",
    "\n",
    "The next line identified the contents of the document as being HTML code\n",
    "\n",
    "> DOCTYPE html\n",
    "\n",
    "The tags `html` and `/html` define everything that goes into the document\n",
    "\n",
    "> html\n",
    "\n",
    "A document typically has a header and a body. They are identified by the `head` and `body` tags\n",
    "\n",
    "> head\n",
    "\n",
    "Statements within the `head` tag are not rendered but provide general information about the document.\n",
    "\n",
    "The `title` tag provides a title that appear in the browsers title and tab bar. \n",
    "\n",
    "> title\n",
    "\n",
    "> <title>Page Title</title>\n",
    "\n",
    "Statements within the `body` describe visible page content.\n",
    "\n",
    "> body\n",
    "\n",
    "The `h1` tag defined a section title.  There are 6 depth levels to sections 1 corresponding to the highest level and 6 to the lowest.  The size of the font used to display the title decreases with the depth of the level. \n",
    "\n",
    "> h1\n",
    "\n",
    "\n",
    "The `p` tag indicates new paragraphs.\n",
    "\n",
    "> p\n",
    "\n",
    "> <p>My first paragraph.</p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Different levels of headers**\n",
    "\n",
    "```html\n",
    "<h1>This is heading 1</h1>\n",
    "<h2>This is heading 2</h2>\n",
    "<h3>This is heading 3</h3>\n",
    "<h4>This is heading 4</h4>\n",
    "<h5>This is heading 5</h5>\n",
    "<h6>This is heading 6</h6> \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important `html` objects \n",
    "\n",
    "**Links**\n",
    "```html\n",
    "<a href=\"http://www.website.com\">Click to go to website.com</a>\n",
    "```\n",
    "\n",
    "**Images**\n",
    "```html\n",
    "<!-- Notice that the image tag has no closing tag and no content outside the opening tag.\n",
    " The alt tag attribute provides accessibility to visually impaired user.\n",
    " The width tag attribute specifies the size of the image.\n",
    "-->\n",
    "<img src=\"Images/smiley.png\" alt=\"smiley face\" \n",
    "          width = '40'>\n",
    "```\n",
    "\n",
    "**Lists**\n",
    "```html\n",
    "<!-- Unordered (bulleted) list -->\n",
    "<ul>\n",
    "  <li>One Element</li>\n",
    "  <li>Another Element</li>\n",
    "</ul>\n",
    "\n",
    "<!-- Ordered (numbered) list -->\n",
    "<ol>\n",
    "  <li>First Ordered Element</li>\n",
    "  <li>Second Ordered Element</li>\n",
    "</ol>\n",
    "```\n",
    "\n",
    "**Tables**\n",
    "```html\n",
    "<table>\n",
    "  <!-- An HTML table is defined as a series of rows (<tr>) -->\n",
    "  <!-- The individual cell (<td>) contents are nested inside rows -->\n",
    "  \n",
    "  <!-- The <tr> tag is optional and is the parent of column headers (<th>) -->\n",
    "  <tr>\n",
    "    <th>First Header</th>\n",
    "    <th>Second Header</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Row 2, Col 1</td>\n",
    "    <td>Row 2, Col 2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Row 3, Col 1</td>\n",
    "    <td>Row 3, Col 2</td>\n",
    "  </tr>\n",
    "</table>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T16:03:55.503923Z",
     "start_time": "2022-09-14T16:03:55.471091Z"
    }
   },
   "outputs": [],
   "source": [
    "more_tags = \"\"\"\n",
    "<html>\n",
    "<head>\n",
    "  <title>More HTML Tags</title>\n",
    "</head>\n",
    "<body>\n",
    "  <h1>This is heading 1</h1>\n",
    "  <h2>This is heading 2</h2>\n",
    "  \n",
    "  <h3>This is heading 3</h3>\n",
    "  <h4>This is heading 4</h4>\n",
    "  <h5>This is heading 5</h5>\n",
    "  <h6>This is heading 6</h6>\n",
    "\n",
    "  <br>\n",
    "  \n",
    "  <a href=\"http://www.website.com\">Click to go to website.com</a>\n",
    "\n",
    "  <p><img src=\"Images/smiley.png\" alt=\"smiley face\" \n",
    "          width = '50'></p>\n",
    "\n",
    "  <ul>\n",
    "    <li>One Element</li>\n",
    "    <li>Another Element</li>\n",
    "  </ul>\n",
    "\n",
    "  <ol>\n",
    "    <li>First Ordered Element</li>\n",
    "    <li>Second Ordered Element</li>\n",
    "  </ol>\n",
    "\n",
    "  <table>\n",
    "    <!-- An HTML table is defined as a series of rows (<tr>) -->\n",
    "    <!-- The individual cell (<td>) contents are nested inside rows -->\n",
    "    <tr>\n",
    "      <!-- The <tr> tag defines a column headers -->\n",
    "      <th>First Header</th>\n",
    "      <th>Second Header</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Row 2, Col 1</td>\n",
    "      <td>Row 2, Col 2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td>Row 3, Col 1</td>\n",
    "    <td>Row 3, Col 2</td>\n",
    "  </tr>\n",
    "  </table>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T16:03:57.167033Z",
     "start_time": "2022-09-14T16:03:57.134022Z"
    }
   },
   "outputs": [],
   "source": [
    "HTML(more_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to learn more about HTML, I recommend the excellent [w3schools website](http://www.w3schools.com/html/html_intro.asp)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing a page's source code\n",
    "\n",
    "Wow!!! You are now an HTML expert. Congratulations! \n",
    "\n",
    "You are now almost ready to start parsing and analyzing a scraped web page. There's just one last item of business we need to discuss before we get started.\n",
    "\n",
    "In order to extract elements of interest from a webpage, you need to know where they sit in the webpage's `HTML` structure .\n",
    "\n",
    "Sadly, really really sadly, **this means that you need to look at the HTML source code before you can start scraping it.**\n",
    "\n",
    "Not only that but, during your web scraping you will be switching back and forth between the actual scraping (we'll get there really soon, I promise!) and the source code.\n",
    "\n",
    "So, how do you view a page's source code then?\n",
    "\n",
    "> To view the **full page** source code:\n",
    ">  1. Right-click anywhere on the webpage **that is not a link**\n",
    ">  2. Click \"View Page Source\" (<kbd>CTRL</kbd>+<kbd>U</kbd>) in Firefox or Chrome, or \"Show page source\" (<kbd>&#8997;</kbd>+<kbd>&#8984;</kbd>+<kbd>U</kbd>) in Safari.\n",
    ">\n",
    ">   In order to view the source code in Safari the Develop menu must be enabled first:\n",
    ">          Preferences > Advanced > Show Develop menu in menu bar\n",
    "    \n",
    "> To view the source code zoomed-in on **a single element** (much better formatting!):\n",
    ">  1. Right-click any element in the page.\n",
    ">  2. Click \"Inspect Element\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping, finally...\n",
    "\n",
    "##  Beautiful Soup, so rich and green, waiting in a hot tureen!\n",
    "\n",
    "(*The Lobster Quadrille*, Alice in Wonderland)\n",
    "\n",
    "You are now ready to start scraping web pages. \n",
    "\n",
    "It all start with a request made using the `requests` package.  This returns a string that we then need to parse.\n",
    "\n",
    "Parsing is a detail oriented -- likely to become frustrating -- job. It would be a complete nightmare without [`BeautifulSoup`](http://www.crummy.com/software/BeautifulSoup/bs4/doc/). You will notice that we already imported it at the top. Yes, this is thinking ahead!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For completely random reasons, we will use the Wikipedia page for a mediocre German soccer player as an exercise. His page is located [here](https://en.wikipedia.org/wiki/Erik_Durm). To simplify our lives\\*, we have already downloaded the page and placed it in the `Data/` folder. \n",
    "\n",
    "\\* **That, and the fact that we do not want to have hundreds of requests for the same page at the same server at the about the same time all from the same IP address (we are all on the same network!). Such behavior will frequently result in you getting blocked from accessing a website!**\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "We start by reading the page into a string and converting it to a `soup` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T16:13:13.239144Z",
     "start_time": "2022-09-14T16:13:13.170187Z"
    }
   },
   "outputs": [],
   "source": [
    "# We specify the encoding of the file here because the page uses non-standard\n",
    "# characters which would result in potential crashes of our code.\n",
    "#\n",
    "data_folder = Path.cwd() / 'Data' \n",
    "filename = data_folder / 'web_scraping_erik_durm_wiki.html'\n",
    "\n",
    "with open(filename, \"r\", encoding = \"utf-8\") as wiki_file:\n",
    "    string_content = wiki_file.read()\n",
    "    soup = BeautifulSoup(string_content, 'lxml')\n",
    "\n",
    "print(type(soup))\n",
    "print()\n",
    "print(f\"-- {soup.text[:60].strip()} --\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching by `tag` type\n",
    "\n",
    "\n",
    "Then, we're going to use the `find` method to find the page's `<title>` tag and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T16:14:29.055859Z",
     "start_time": "2022-09-14T16:14:29.021024Z"
    }
   },
   "outputs": [],
   "source": [
    "title = soup.find('title')  \n",
    "print(f\"The method .find() returns a {type(title)} object\\n\")\n",
    "\n",
    "print(f\"The text attribute of the tag object is:\\n\\t{title.text}\\n\")\n",
    "\n",
    "print(f\"which is a {type(title.text)} object\\n\")\n",
    "\n",
    "print(f\"The contents attribute of the tag object is:\\n\\t{title.contents}\\n\")\n",
    "\n",
    "print(f\"which is a {type(title.contents)} object\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "Beautiful Soup converts HTML tags into its own `tag` objects that, as you can see, have many useful attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T16:17:31.728539Z",
     "start_time": "2022-09-14T16:17:31.687915Z"
    }
   },
   "outputs": [],
   "source": [
    "print(title.name) # The type of tag\n",
    "\n",
    "help(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a tag has any html attributes, they can be accessed in a very \"pythonic\" way. That is, they are organized as a dictionary!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T16:21:54.602633Z",
     "start_time": "2022-09-14T16:21:54.569428Z"
    }
   },
   "outputs": [],
   "source": [
    "h_tag = soup.find('h1')\n",
    "\n",
    "for x in h_tag.attrs:\n",
    "    print( f\"Key: {x:5} -- Value: {h_tag.attrs[x]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One could go on searching for instance of a `tag` one at a time.  \n",
    "\n",
    "\n",
    "## Finding multiple matches\n",
    "\n",
    "To this end, we must use the method `.find_next()`.   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T16:21:57.762475Z",
     "start_time": "2022-09-14T16:21:57.733918Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finds first instance\n",
    "#\n",
    "header1 = soup.find('h2')\n",
    "print(header1.text)\n",
    "\n",
    "# searching of previously found object gives us the next instance\n",
    "#\n",
    "header2 = header1.find_next('h2')\n",
    "print(header2.text)\n",
    "\n",
    "# And again\n",
    "#\n",
    "header3 = header2.find_next('h2')\n",
    "print(header3.text)\n",
    "\n",
    "# If we just try to find instead of find_next, we find nothing\n",
    "#\n",
    "header3 = header2.find('h2')\n",
    "print(header3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "We can also we can also retrieve all instances at once.  Now, we should expect to get a `list` of `tag` objects in return..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T16:24:59.507665Z",
     "start_time": "2022-09-14T16:24:59.476056Z"
    }
   },
   "outputs": [],
   "source": [
    "headers = soup.find_all('h2')\n",
    "\n",
    "print(f\"The variable headers is a {type(headers)} object\\n\")\n",
    "\n",
    "print(f\"Because it is list-like, it has a length: {len(headers)}\\n\")\n",
    "\n",
    "print(f\"Its first item is {headers[0]} and its last is {headers[-1]}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda update beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T16:28:13.089757Z",
     "start_time": "2022-09-14T16:28:13.057917Z"
    }
   },
   "outputs": [],
   "source": [
    "for header in headers[:2]:\n",
    "    print(f\"++++\\t{header.name} -- {header.contents}\")\n",
    "    \n",
    "    for item in header.contents:\n",
    "        print(f\"\\t\\t--{item}\")\n",
    "        print(f\"\\t\\t--{type(item)}\")\n",
    "        print(f\"\\t\\t--{item.text}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "\n",
    "Another `tag` that that is frequently useful and that I will use to demonstrate some other useful attributes is the one for links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T16:40:29.652736Z",
     "start_time": "2022-09-14T16:40:29.602434Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "links = soup.find_all('a')\n",
    "print(len(links))\n",
    "\n",
    "for link in links[:5]:  \n",
    "    # href represents the target of the link\n",
    "    # Where the link actually goes to!\n",
    "    print(f\"\\n-- {link}\")\n",
    "    print(f\"\\t Attributes of the tag object: {link.attrs}\")\n",
    "    print(f\"\\t\\t Value of the link: {link.get('href')}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching using attribute information\n",
    "\n",
    "Some `Tag` elements have attributes associated with them. These includes `id`, `class_`, `href`.  Our search can restrict results to attributes with a specific value or to results where the attribute type is included.\n",
    "\n",
    "Note that we must use `class_` instead of `class` to avoid conflicts with Python's built-in keyword. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T16:49:48.912454Z",
     "start_time": "2022-09-14T16:49:48.869561Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve the element with the attribute \"id\" equal to \"Early_career\"\n",
    "tag = soup.find(id=\"Early_career\")\n",
    "print(tag)\n",
    "print(tag.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T16:50:32.449891Z",
     "start_time": "2022-09-14T16:50:32.412651Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve all elements with an href attribute\n",
    "all_links = soup.find_all(href=True)\n",
    "print(len(all_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T16:50:49.177408Z",
     "start_time": "2022-09-14T16:50:49.144305Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Retrieve inline citations -- they are <sup> elements with the class \"reference\"\n",
    "soup.find_all('sup', class_ = 'reference')[5:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T19:54:15.975108Z",
     "start_time": "2022-07-18T19:54:15.933033Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve all tags with class=mw-headline and an id attribute (regardless of value)\n",
    "soup.find_all(attrs={\"class\": \"mw-headline\", \"id\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Tag` attributes\n",
    "\n",
    "`class` and `id` are special HTML attributes that allow for a rich connection between HTML and CSS and Javascript. Feel free to google the subject. We won't go into the details here. Just know that:\n",
    "\n",
    "* The `id` attribute is used to uniquely identify a tag. This means that all `id` attributes should have different values in a webpage.\n",
    "\n",
    "* The `class` attribute is used to identify tags which share certain properties. A tag can have more than one `class` value:\n",
    "```html\n",
    "   <!-- Separate extra classes by a space -->\n",
    "   <tag class=\"first_class second_class\">...</tag>\n",
    "```\n",
    "\n",
    "In the above example, notice that all reference elements (`<sup>` tags) have the same `class` value but different `id` values.\n",
    "\n",
    "**Note that not all webpage follow this simple rule.  Some will repeat `id` values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigating the HTML tree with BeautifulSoup\n",
    "\n",
    "\n",
    "Besides being able to search elements anywhere on the whole html tree, beautiful soup also allows you to navigate the tree in any direction.\n",
    "\n",
    "Let's try to get at the first paragraph (`<p>`) in the `Club career` section starting from the section's title tag.\n",
    "\n",
    "Here's the relevant HTML snippet:\n",
    "\n",
    "```html\n",
    "    <h2>\n",
    "      <span class=\"mw-headline\" id=\"Club_career\">Club career</span>\n",
    "      <span class=\"mw-editsection\">\n",
    "        <span class=\"mw-editsection-bracket\">[</span>\n",
    "        <a href=\"/w/index.php?title=Erik_Durm&amp;action=edit&amp;section=1\" title=\"Edit section: Club career\">edit</a>\n",
    "        <span class=\"mw-editsection-bracket\">]</span>\n",
    "      </span>\n",
    "    </h2>\n",
    "    <h3>\n",
    "      <span class=\"mw-headline\" id=\"Early_career\">Early career</span>\n",
    "      <span class=\"mw-editsection\">\n",
    "        <span class=\"mw-editsection-bracket\">[</span>\n",
    "        <a href=\"/w/index.php?title=Erik_Durm&amp;action=edit&amp;section=2\" title=\"Edit section: Early career\">edit</a>\n",
    "        <span class=\"mw-editsection-bracket\">]</span>\n",
    "      </span>\n",
    "    </h3>\n",
    "    <p>Durm began his club career in 1998 at the academy of SG Rieschweiler....</p>\n",
    "```\n",
    "\n",
    "The actual text appear in the `HTML` code after that `p tag`, which appears both in the page and in the code after *Club career* title: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T20:02:14.394619Z",
     "start_time": "2022-07-18T20:02:14.360812Z"
    }
   },
   "outputs": [],
   "source": [
    "section_headline = soup.find( id = 'Club_career')\n",
    "print(section_headline)\n",
    "print()\n",
    "\n",
    "print(section_headline.text)\n",
    "print()\n",
    "\n",
    "print(section_headline.contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `contents` attribute gives us access to everything contained within the relevant `tag` as a `list`. \n",
    "\n",
    "In this case we find only the visible text of the tag.\n",
    "\n",
    "Looking at the webpage snippet, we see that the tag `<p>` is at the **same level** as the `tags` `<h2>` and `<h3>`.  \n",
    "\n",
    "One way to navigate there -- think filesystem tree -- is to ascend one level in the tree, in this case, to the `h2 tag`.\n",
    "\n",
    "\n",
    "The `h2 tag` has two siblings (that we can see in the snippet):  and `h3 tag` and a `p tag`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T20:10:36.600673Z",
     "start_time": "2022-07-18T20:10:36.568466Z"
    }
   },
   "outputs": [],
   "source": [
    "parent_of_title = section_headline.parent  # Up one level\n",
    "\n",
    "print(f\"The section_headline is of type:\\t{section_headline.name}\")\n",
    "print()\n",
    "\n",
    "print(f\"The parent of section_headline is of type:\\t{parent_of_title.name}\")\n",
    "print()\n",
    "\n",
    "print(parent_of_title.contents)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T20:32:59.101784Z",
     "start_time": "2022-07-18T20:32:59.068919Z"
    }
   },
   "outputs": [],
   "source": [
    "one_step = parent_of_title.nextSibling\n",
    "print(f\"---- one_step is a \\t{type(one_step)}\\n\")\n",
    "\n",
    "print(f\"--It has the value:\\n--\\n--{one_step}--\\n\")\n",
    "\n",
    "two_steps = parent_of_title.nextSibling.nextSibling\n",
    "print(f\"---- two_steps is of type:\\t{type(two_steps)}\\n\")\n",
    "\n",
    "print(f\"It has the value:\\n--\\n--{two_steps}--\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only at the `<h3>` tag even though we moved past two siblings.  \n",
    "\n",
    "The reason is that some of the `siblings` in the soup are not actual `HTML` elements. An empty line could be processed as an element in the soup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T20:33:01.990796Z",
     "start_time": "2022-07-18T20:33:01.959280Z"
    }
   },
   "outputs": [],
   "source": [
    "three_steps = two_steps.nextSibling\n",
    "print(f\"---- three_steps is a \\t{type(three_steps)}\\n\")\n",
    "\n",
    "print(f\"--It has the value:\\n--\\n--{three_steps}--\\n\")\n",
    "\n",
    "four_steps = three_steps.nextSibling\n",
    "print(f\"---- four_steps is of type:\\t{type(four_steps)}\\n\")\n",
    "\n",
    "print(f\"It has the value:\\n--\\n--{four_steps}--\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "\n",
    "That is what we want: the fourth sibling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T20:34:15.669524Z",
     "start_time": "2022-07-18T20:34:15.636969Z"
    }
   },
   "outputs": [],
   "source": [
    "print(four_steps.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T20:34:16.720594Z",
     "start_time": "2022-07-18T20:34:16.689609Z"
    }
   },
   "outputs": [],
   "source": [
    "print(four_steps.contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, it is very sad.  \n",
    "\n",
    "**Web-scrapping involves a lot of trial and error.**\n",
    "\n",
    "There is no getting around of it. There is just to much that is left to the developer's choice, so even two webpages that *look the same* may, under the hood, **be coded quite differently**.\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "We can the contents of our desired element is a list.  Let's obtain the number of elements and check what they contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T20:40:45.630176Z",
     "start_time": "2022-07-18T20:40:45.597245Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(four_steps.contents))\n",
    "\n",
    "for i, item in enumerate(four_steps.contents):\n",
    "    print(f\"{i:2} : {str(item)[:80]}\")\n",
    "    \n",
    "# print(two_steps.contents[1])\n",
    "# print(two_steps.contents[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "To review: in order to find the desired tag, we choose a easily identifiable starting point -- `id` is great because its value *should* be unique -- and then navigate the HTML tree to the correct parent and transversed siblings until we got to the right one. \n",
    "\n",
    "Clearly, this is not a very elegant solution. \n",
    "\n",
    "If there were hundreds of siblings that would have been very cumbersome. \n",
    "\n",
    "So, naturally, `Python` developers thought of a better way to do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T20:41:51.722068Z",
     "start_time": "2022-07-18T20:41:51.690793Z"
    }
   },
   "outputs": [],
   "source": [
    "p_sibling = parent_of_title.find_next_sibling('p')\n",
    "print(f\"---- four_steps is of type:\\t{type(p_sibling)}\\n\")\n",
    "\n",
    "print(f\"It has the value:\\n--\\n--{p_sibling}--\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much nicer!\n",
    "\n",
    "Besides the `.find_next_sibling` method, there are also `.find_previous_sibling`, `.find_next_children`, `.find_previous_children`, and many others.\n",
    "\n",
    "The [Beautiful Soup documentation](http://www.crummy.com/software/BeautifulSoup/bs4/doc/) has a comprehensive list of all these methods. \n",
    "\n",
    "**There is no need to memorize all of them.**\n",
    "\n",
    "It's more important to realize that, as with any programming language, there is more than one way to get any element of the `HTML` tree. \n",
    "\n",
    "The trick, most of the time, is to *pick a good starting point* from where to start the scraping.\n",
    "\n",
    "Wisdom, is to realize that, most of the time, there is a method that does what you want.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping images from a webpage\n",
    "\n",
    "You can also use Beautiful Soup to get the source of an image from a webpage. It works just the same as for text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-25T21:45:51.010929Z",
     "start_time": "2022-07-25T21:45:50.969565Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, image in enumerate( soup.find_all('img') ):\n",
    "    print(f\"{i:>2} -- {str(image)[:80]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pinpoint a specific image and get its attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-25T21:45:55.647820Z",
     "start_time": "2022-07-25T21:45:55.613600Z"
    }
   },
   "outputs": [],
   "source": [
    "images = soup.find_all('img')\n",
    "\n",
    "print(images[0].attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "\n",
    "Then, we can display the image using its `src` attribute.\n",
    "\n",
    "Below, you can see how it is done if it is a file you have downloaded.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-25T21:46:00.690393Z",
     "start_time": "2022-07-25T21:46:00.649806Z"
    }
   },
   "outputs": [],
   "source": [
    "print(data_folder / images[0]['src'])\n",
    "\n",
    "for j in range(2):\n",
    "    display(Image(filename =  data_folder / images[j]['src']))\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have the `url`, then this is how you do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-25T21:46:07.863387Z",
     "start_time": "2022-07-25T21:46:07.831780Z"
    }
   },
   "outputs": [],
   "source": [
    "real_url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/Erik_Durm_2014_%28cropped%29.jpg/440px-Erik_Durm_2014_%28cropped%29.jpg' \n",
    "display(Image(url = real_url, width= 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about getting all the `urls` in the page?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
